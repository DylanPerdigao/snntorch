{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b43216d4a624402a9e2b6e3dfbe89c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_891e63f1befd4c59b92b5902a01865e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f46980045b44bb0a56276f43ff5ef45",
              "IPY_MODEL_ee29ef27939c4c5da8641b299ebb4f0c"
            ]
          }
        },
        "891e63f1befd4c59b92b5902a01865e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f46980045b44bb0a56276f43ff5ef45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7aa0ab7e3bc047f2bfcf29ec7e5e7d33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7c1a47d7b9e459194fe236b4081ff74"
          }
        },
        "ee29ef27939c4c5da8641b299ebb4f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9fc4fded8f784f6f920b01927b7f1c90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1457595.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad991bac608743c7a492216f8edf29f0"
          }
        },
        "7aa0ab7e3bc047f2bfcf29ec7e5e7d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7c1a47d7b9e459194fe236b4081ff74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fc4fded8f784f6f920b01927b7f1c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad991bac608743c7a492216f8edf29f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a064ea45da14cfd901232a4f47b00db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2d8745df9c44efe8712986184014712",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc7c63b8a23c43d38d88913560f5956f",
              "IPY_MODEL_2e76168e673d4689903fad871e088baf"
            ]
          }
        },
        "f2d8745df9c44efe8712986184014712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc7c63b8a23c43d38d88913560f5956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94c8e530872d4cd682c83ade19cb3eb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17dda6f0c2c54d748bbf565f5fd35e9b"
          }
        },
        "2e76168e673d4689903fad871e088baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a61096aca4f045ce92bcc743a5077b47",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:01&lt;00:00, 29221.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dede33eb2bd24cc3ba28e7a05efc0533"
          }
        },
        "94c8e530872d4cd682c83ade19cb3eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17dda6f0c2c54d748bbf565f5fd35e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a61096aca4f045ce92bcc743a5077b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dede33eb2bd24cc3ba28e7a05efc0533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad9906c3e4a64904abb602cf53b27c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a27b937dda243129cba36ece9b0ef57",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36c5dd2c235441dc83be07dc23b1f897",
              "IPY_MODEL_1bf6904b900249f1aa6e4495f19ef1a8"
            ]
          }
        },
        "4a27b937dda243129cba36ece9b0ef57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36c5dd2c235441dc83be07dc23b1f897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26cca88260164470a0918452fa2ae480",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cdda018f1784bbfbbfc447fbd72eb33"
          }
        },
        "1bf6904b900249f1aa6e4495f19ef1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19f8ed71f4a042bb91367945ebf12cf1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:18&lt;00:00, 1059523.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08f60a41f01a464486bd164668eca50d"
          }
        },
        "26cca88260164470a0918452fa2ae480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cdda018f1784bbfbbfc447fbd72eb33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19f8ed71f4a042bb91367945ebf12cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08f60a41f01a464486bd164668eca50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb797f738169411d841a6a2f04d0a8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b624cdf8901b4e12a928b0ef13fa7c13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bcc60df53c74ce585518193792818fd",
              "IPY_MODEL_ae81921ff13b494db89599d92b570162"
            ]
          }
        },
        "b624cdf8901b4e12a928b0ef13fa7c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bcc60df53c74ce585518193792818fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dfdd6f59e487425f9c546e720ecb5a9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0eb8a477967d4f80803daaebf6af3460"
          }
        },
        "ae81921ff13b494db89599d92b570162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c18e92215aaa47629d3a53f80f39cee3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:06&lt;00:00, 1294.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36470559bda24c7db3f88f740ae4a28d"
          }
        },
        "dfdd6f59e487425f9c546e720ecb5a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0eb8a477967d4f80803daaebf6af3460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c18e92215aaa47629d3a53f80f39cee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36470559bda24c7db3f88f740ae4a28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/binary_weights/examples/binary_snn_no_conflict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOyd0FJMbWki"
      },
      "source": [
        "# **SNN with binary weights**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "S733HbldaB40"
      },
      "source": [
        "# Gradient-based Learning in Convolutional Spiking Neural Networks\n",
        "In this tutorial, we'll use a convolutional neural network (CNN) to classify the MNIST dataset.\n",
        "We will use the backpropagation through time (BPTT) algorithm to do so. This tutorial is largely the same as tutorial 2, just with a different network architecture to show how to integrate convolutions with snnTorch.\n",
        "\n",
        "If running in Google Colab:\n",
        "* Ensure you are connected to GPU by checking Runtime > Change runtime type > Hardware accelerator: GPU\n",
        "* Next, install the Test PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YgGUk8EJaB41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb18cf5e-22da-4d86-e6a7-1299137258d9"
      },
      "source": [
        "# Install the test PyPi Distribution of snntorch\n",
        "\n",
        "# !pip uninstall snntorch\n",
        "!pip install -i https://test.pypi.org/simple/ snntorch\n",
        "# !pip install git+https://github.com/jeshraghian/snntorch.git@binary_weights#egg=snntorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Collecting snntorch\n",
            "  Downloading https://test-files.pythonhosted.org/packages/4e/71/23d35f42916ae8ec8a1a3bd3dc98804a09587ca9b6971e0ebaa80a6c5234/snntorch-0.0.9-py3-none-any.whl\n",
            "Installing collected packages: snntorch\n",
            "Successfully installed snntorch-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_UAKn7UoaB41"
      },
      "source": [
        "## 1. Setting up the Static MNIST Dataset\n",
        "### 1.1. Import packages and setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JGneJnSiaB42"
      },
      "source": [
        "import snntorch as snn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PWL3FQSSaB42"
      },
      "source": [
        "### 1.2 Define network and SNN parameters\n",
        "We will use a 2conv-2MaxPool-FCN architecture for a sequence of 25 time steps.\n",
        "\n",
        "* `alpha` is the decay rate of the synaptic current of a neuron\n",
        "* `beta` is the decay rate of the membrane potential of a neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kvzf29tIaB42"
      },
      "source": [
        "# Network Architecture\n",
        "num_inputs = 28*28\n",
        "num_outputs = 10\n",
        "num_hidden = 1000\n",
        "# Training Parameters\n",
        "batch_size=128\n",
        "data_path='/data/mnist'\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 32\n",
        "time_step = 1e-3\n",
        "# tau_mem = 6.5e-4\n",
        "# tau_syn = 5.5e-4\n",
        "# alpha = float(np.exp(-time_step/tau_syn))\n",
        "# beta = float(np.exp(-time_step/tau_mem))\n",
        "alpha = 0.3\n",
        "beta = 0.3\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4_5wuLk0aB43"
      },
      "source": [
        "### 1.3 Download MNIST Dataset\n",
        "To see how to construct a validation set, refer to Tutorial 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WJO7iy-7aB43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "b43216d4a624402a9e2b6e3dfbe89c2a",
            "891e63f1befd4c59b92b5902a01865e1",
            "0f46980045b44bb0a56276f43ff5ef45",
            "ee29ef27939c4c5da8641b299ebb4f0c",
            "7aa0ab7e3bc047f2bfcf29ec7e5e7d33",
            "d7c1a47d7b9e459194fe236b4081ff74",
            "9fc4fded8f784f6f920b01927b7f1c90",
            "ad991bac608743c7a492216f8edf29f0",
            "5a064ea45da14cfd901232a4f47b00db",
            "f2d8745df9c44efe8712986184014712",
            "fc7c63b8a23c43d38d88913560f5956f",
            "2e76168e673d4689903fad871e088baf",
            "94c8e530872d4cd682c83ade19cb3eb2",
            "17dda6f0c2c54d748bbf565f5fd35e9b",
            "a61096aca4f045ce92bcc743a5077b47",
            "dede33eb2bd24cc3ba28e7a05efc0533",
            "ad9906c3e4a64904abb602cf53b27c71",
            "4a27b937dda243129cba36ece9b0ef57",
            "36c5dd2c235441dc83be07dc23b1f897",
            "1bf6904b900249f1aa6e4495f19ef1a8",
            "26cca88260164470a0918452fa2ae480",
            "5cdda018f1784bbfbbfc447fbd72eb33",
            "19f8ed71f4a042bb91367945ebf12cf1",
            "08f60a41f01a464486bd164668eca50d",
            "fb797f738169411d841a6a2f04d0a8a1",
            "b624cdf8901b4e12a928b0ef13fa7c13",
            "0bcc60df53c74ce585518193792818fd",
            "ae81921ff13b494db89599d92b570162",
            "dfdd6f59e487425f9c546e720ecb5a9f",
            "0eb8a477967d4f80803daaebf6af3460",
            "c18e92215aaa47629d3a53f80f39cee3",
            "36470559bda24c7db3f88f740ae4a28d"
          ]
        },
        "outputId": "de715af4-1350-4b3e-d4b9-bd87e517e1e3"
      },
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b43216d4a624402a9e2b6e3dfbe89c2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a064ea45da14cfd901232a4f47b00db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad9906c3e4a64904abb602cf53b27c71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb797f738169411d841a6a2f04d0a8a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6_guKA__aB44"
      },
      "source": [
        "### 1.4 Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cQzrUSKRaB44"
      },
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "jHBwr32UaB44"
      },
      "source": [
        "## 2. Define Network\n",
        "To define our network, we will import two functions from the `snntorch.neuron` module, which contains a series of neuron models and related functions.\n",
        "snnTorch treats neurons as activations with recurrent connections, so that it integrates smoothly with PyTorch's pre-existing layer functions.\n",
        "* `snntorch.neuron.LIF` is a simple Leaky Integrate and Fire (LIF) neuron. Specifically, it uses Stein's model which assumes instantaneous rise times for synaptic current and membrane potential.\n",
        "* `snntorch.neuron.FastSigmoidSurrogate` defines separate forward and backward functions. The forward function is a Heaviside step function for spike generation. The backward function is the derivative of a fast sigmoid function, to ensure continuous differentiability.\n",
        "FSS is mostly derived from:\n",
        "\n",
        ">Neftci, E. O., Mostafa, H., and Zenke, F. (2019) Surrogate Gradient Learning in Spiking Neural Networks. https://arxiv.org/abs/1901/09948\n",
        "\n",
        "`snn.neuron.slope` is a variable that defines the slope of the backward surrogate.\n",
        "TO-DO: Include visualisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2JKR_90daB45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "88309a26-140e-45bb-9d15-7530d9ec3a00"
      },
      "source": [
        "spike_grad = snn.FastSigmoidSurrogate.apply\n",
        "snn.slope = 50"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1502cfba5f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspike_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastSigmoidSurrogate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'snntorch' has no attribute 'FastSigmoidSurrogate'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "LaXzsI6baB45"
      },
      "source": [
        "Now we can define our SNN. Defining an instance of `LIF` requires three arguments: 1) the surrogate spiking function, 2) $I_{syn}$ decay rate, $\\alpha$, and 3) $V_{mem}$ decay rate, $\\beta$.\n",
        "\n",
        "The LIF neuron is simply treated as a recurrent activation. It requires initialization of the post-synaptic spikes `spk1` and `spk2`, the synaptic current `syn1` and `syn2`, and the membrane potential `mem1` and `mem2`.\n",
        "\n",
        "We will use the final layer spikes and membrane for determining loss and accuracy, so we will record and return their histories in `spk3_rec` and `mem3_rec`.\n",
        "\n",
        "Keep in mind, the dataset we are using is just static MNIST. I.e., it is *not* time-varying.\n",
        "Therefore, we pass the same MNIST sample to the input at each time step.\n",
        "This is handled in the line `cur1 = F.max_pool2d(self.conv1(x), 2)`, where `x` is the same input over the whole for-loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zAnnWfGyfhkf"
      },
      "source": [
        "### Binarized Layer Modules\n",
        "``Binarize`` converts weights to {-1, 1}.\n",
        "Remove `.mul_(2).add_(1)` for {0, 1}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "blVwJakcaB46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b257f02-74a2-4c0b-9ac6-fb0be25a8533"
      },
      "source": [
        "import pdb\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Binarize(tensor,quant_mode='det'):\n",
        "    if quant_mode=='det':\n",
        "        return tensor.sign()\n",
        "        # tmp = tensor.clone()\n",
        "        # tmp[tensor>0] = 1\n",
        "        # tmp[tensor==0] = 0\n",
        "        # tmp[tensor<0] = -1\n",
        "        # return tmp\n",
        "    else:\n",
        "        return tensor.add_(1).div_(2).add_(torch.rand(tensor.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)\n",
        "\n",
        "\n",
        "class HingeLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HingeLoss,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def hinge_loss(self,input,target):\n",
        "            #import pdb; pdb.set_trace()\n",
        "            output=self.margin-input.mul(target)\n",
        "            output[output.le(0)]=0\n",
        "            return output.mean()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.hinge_loss(input,target)\n",
        "\n",
        "class SqrtHingeLossFunction(Function):\n",
        "    def __init__(self):\n",
        "        super(SqrtHingeLossFunction,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        output=self.margin-input.mul(target)\n",
        "        output[output.le(0)]=0\n",
        "        self.save_for_backward(input, target)\n",
        "        loss=output.mul(output).sum(0).sum(1).div(target.numel())\n",
        "        return loss\n",
        "\n",
        "    def backward(self,grad_output):\n",
        "       input, target = self.saved_tensors\n",
        "       output=self.margin-input.mul(target)\n",
        "       output[output.le(0)]=0\n",
        "       import pdb; pdb.set_trace()\n",
        "       grad_output.resize_as_(input).copy_(target).mul_(-2).mul_(output)\n",
        "       grad_output.mul_(output.ne(0).float())\n",
        "       grad_output.div_(input.numel())\n",
        "       return grad_output,grad_output\n",
        "\n",
        "def Quantize(tensor,quant_mode='det',  params=None, numBits=8):\n",
        "    tensor.clamp_(-2**(numBits-1),2**(numBits-1))\n",
        "    if quant_mode=='det':\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().div(2**(numBits-1))\n",
        "    else:\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().add(torch.rand(tensor.size()).add(-0.5)).div(2**(numBits-1))\n",
        "        quant_fixed(tensor, params)\n",
        "    return tensor\n",
        "\n",
        "# import torch.nn._functions as tnnf\n",
        "\n",
        "\n",
        "class BinarizeLinear(nn.Linear):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if input.size(1) != 784:\n",
        "            input.data=Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "        out = nn.functional.linear(input, self.weight)\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1).expand_as(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BinarizeConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeConv2d, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.size(1) != 3:\n",
        "            input.data = Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "\n",
        "        out = nn.functional.conv2d(input, self.weight, None, self.stride,\n",
        "                                   self.padding, self.dilation, self.groups)\n",
        "\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1, 1, 1).expand_as(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuKfWeZrh50P"
      },
      "source": [
        "class LIF(nn.Module):\n",
        "    \"\"\"Parent class for leaky integrate and fire neuron models.\"\"\"\n",
        "    instances = []\n",
        "    def __init__(self, alpha, beta, threshold=1.0, spike_grad=None):\n",
        "        super(LIF, self).__init__()\n",
        "        LIF.instances.append(self)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.threshold = threshold\n",
        "\n",
        "        if spike_grad is None:\n",
        "            self.spike_grad = self.Heaviside.apply\n",
        "        else:\n",
        "            self.spike_grad = spike_grad\n",
        "\n",
        "    def fire(self, mem):\n",
        "        \"\"\"Generates spike if mem > threshold.\n",
        "        Returns spk and reset.\"\"\"\n",
        "        mem_shift = mem - self.threshold\n",
        "        spk = self.spike_grad(mem_shift).to(device)\n",
        "        reset = torch.zeros_like(mem)\n",
        "        spk_idx = (mem_shift > 0)\n",
        "        reset[spk_idx] = torch.ones_like(mem)[spk_idx]\n",
        "        return spk, reset\n",
        "\n",
        "    def fire_single(self, mem):\n",
        "        \"\"\"Generates spike if mem > threshold.\n",
        "        Returns spk and reset.\"\"\"\n",
        "        mem_shift = mem - self.threshold\n",
        "        \n",
        "        index = torch.argmax(mem_shift, dim=-1)\n",
        "        \n",
        "        spk_tmp = self.spike_grad(mem_shift)\n",
        "\n",
        "        mask_spk1 = torch.zeros_like(spk_tmp)\n",
        "        # print(mem.size())\n",
        "        # print(index.size())\n",
        "        mask_spk1[torch.arange(mem_shift.size()[0]), index] = 1\n",
        "        spk = (spk_tmp * mask_spk1).to(device)\n",
        "        # print(spk[0])\n",
        "        reset = torch.zeros_like(mem)\n",
        "        spk_idx = (mem_shift > 0)\n",
        "        reset[spk_idx] = torch.ones_like(mem)[spk_idx]\n",
        "        return spk, reset\n",
        "\n",
        "    @classmethod\n",
        "    def clear_instances(cls):\n",
        "      cls.instances = []\n",
        "\n",
        "    @staticmethod\n",
        "    def init_stein(batch_size, *args):\n",
        "        \"\"\"Used to initialize syn, mem and spk.\n",
        "        *args are the input feature dimensions.\n",
        "        E.g., batch_size=128 and input feature of size=1x28x28 would require init_hidden(128, 1, 28, 28).\"\"\"\n",
        "        syn = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        mem = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        spk = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "\n",
        "        return spk, syn, mem\n",
        "\n",
        "    @staticmethod\n",
        "    def init_srm0(batch_size, *args):\n",
        "        \"\"\"Used to initialize syn_pre, syn_post, mem and spk.\n",
        "        *args are the input feature dimensions.\n",
        "        E.g., batch_size=128 and input feature of size=1x28x28 would require init_hidden(128, 1, 28, 28).\"\"\"\n",
        "        syn_pre = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        syn_post = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        mem = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "        spk = torch.zeros((batch_size, *args), device=device, dtype=dtype)\n",
        "\n",
        "        return spk, syn_pre, syn_post, mem\n",
        "\n",
        "    @staticmethod\n",
        "    def detach(*args):\n",
        "        \"\"\"Used to detach input arguments from the current graph.\n",
        "        Intended for use in truncated backpropagation through time where hidden state variables are global variables.\"\"\"\n",
        "        for state in args:\n",
        "            state.detach_()\n",
        "\n",
        "    @staticmethod\n",
        "    def zeros(*args):\n",
        "        \"\"\"Used to clear hidden state variables to zero.\n",
        "            Intended for use where hidden state variables are global variables.\"\"\"\n",
        "        for state in args:\n",
        "            state = torch.zeros_like(state)\n",
        "\n",
        "    @staticmethod\n",
        "    class Heaviside(torch.autograd.Function):\n",
        "        \"\"\"Default and non-approximate spiking function for neuron.\n",
        "        Forward pass: Heaviside step function.\n",
        "        Backward pass: Dirac Delta clipped to 1 at x>0 instead of inf at x=1.\n",
        "        This assumption holds true on the basis that a spike occurs as long as x>0 and the following time step incurs a reset.\"\"\"\n",
        "\n",
        "        @staticmethod\n",
        "        def forward(ctx, input_):\n",
        "            ctx.save_for_backward(input_)\n",
        "            out = torch.zeros_like(input_)\n",
        "            out[input_ > 0] = 1.0\n",
        "            return out\n",
        "\n",
        "        @staticmethod\n",
        "        def backward(ctx, grad_output):\n",
        "            input_, = ctx.saved_tensors\n",
        "            grad_input = grad_output.clone()\n",
        "            grad_input[input_ < 0] = 0.0\n",
        "            grad = grad_input\n",
        "            return grad\n",
        "\n",
        "class Stein_single(LIF):\n",
        "    \"\"\"\n",
        "    Stein's model of the leaky integrate and fire neuron.\n",
        "    The synaptic current jumps upon spike arrival, which causes a jump in membrane potential.\n",
        "    Synaptic current and membrane potential decay exponentially with rates of alpha and beta, respectively.\n",
        "    For mem[T] > threshold, spk[T+1] = 0 to account for axonal delay.\n",
        "\n",
        "    For further reading, see:\n",
        "    R. B. Stein (1965) A theoretical analysis of neuron variability. Biophys. J. 5, pp. 173-194.\n",
        "    R. B. Stein (1967) Some models of neuronal variability. Biophys. J. 7. pp. 37-68.\"\"\"\n",
        "\n",
        "    def __init__(self, alpha, beta, threshold=1.0, num_inputs=False, spike_grad=None, batch_size=False, hidden_init=False):\n",
        "        super(Stein_single, self).__init__(alpha, beta, threshold, spike_grad)\n",
        "\n",
        "        self.num_inputs = num_inputs\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_init = hidden_init\n",
        "\n",
        "        if self.hidden_init:\n",
        "            if not self.num_inputs:\n",
        "                raise ValueError(\"num_inputs must be specified to initialize hidden states as instance variables.\")\n",
        "            elif not self.batch_size:\n",
        "                raise ValueError(\"batch_size must be specified to initialize hidden states as instance variables.\")\n",
        "            elif hasattr(self.num_inputs, '__iter__'):\n",
        "                self.spk, self.syn, self.mem = self.init_stein(self.batch_size, *(self.num_inputs)) # need to automatically call batch_size\n",
        "            else:\n",
        "                self.spk, self.syn, self.mem = self.init_stein(self.batch_size, self.num_inputs)\n",
        "\n",
        "    def forward(self, input_, syn, mem):\n",
        "        if not self.hidden_init:\n",
        "            spk, reset = self.fire_single(mem)\n",
        "            syn = self.alpha * syn + input_\n",
        "            mem = self.beta * mem + syn - reset\n",
        "\n",
        "            return spk, syn, mem\n",
        "\n",
        "        # intended for truncated-BPTT where instance variables are hidden states\n",
        "        if self.hidden_init:\n",
        "            self.spk, self.reset = self.fire(self.mem)\n",
        "            self.syn = self.alpha * self.syn + input_\n",
        "            self.mem = self.beta * self.mem + self.syn - self.reset\n",
        "\n",
        "            return self.spk, self.syn, self.mem\n",
        "\n",
        "    @classmethod\n",
        "    def detach_hidden(cls):\n",
        "        \"\"\"Used to detach hidden states from the current graph.\n",
        "        Intended for use in truncated backpropagation through time where hidden state variables are instance variables.\"\"\"\n",
        "\n",
        "        for layer in range(len(cls.instances)):\n",
        "            cls.instances[layer].spk.detach_()\n",
        "            cls.instances[layer].syn.detach_()\n",
        "            cls.instances[layer].mem.detach_()\n",
        "\n",
        "    @classmethod\n",
        "    def zeros_hidden(cls):\n",
        "        \"\"\"Used to clear hidden state variables to zero.\n",
        "        Intended for use where hidden state variables are instance variables.\"\"\"\n",
        "\n",
        "        for layer in range(len(cls.instances)):\n",
        "            cls.instances[layer].spk = torch.zeros_like(cls.instances[layer].spk)\n",
        "            cls.instances[layer].syn = torch.zeros_like(cls.instances[layer].syn)\n",
        "            cls.instances[layer].mem = torch.zeros_like(cls.instances[layer].mem)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZNySTB6wfhkk"
      },
      "source": [
        "Network: Low precision forward pass, high precision backprop (Additional Mod in Optimization method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZAxmcjuefhkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1465c1-8fd2-43c8-ee0a-88324e08ec9f"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        # self.bn0 = nn.BatchNorm1d(784)\n",
        "        self.fc1 = BinarizeLinear(784, num_hidden)\n",
        "        self.lif1 = Stein_single(alpha=alpha, beta=beta)\n",
        "\n",
        "        self.fc2 = BinarizeLinear(num_hidden, num_outputs)\n",
        "        self.lif2 = Stein_single(alpha=alpha, beta=beta)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "        self.idx1 = torch.arange(batch_size)\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "            # index = torch.argmax(spk1_tmp, dim=1)\n",
        "            # mask_spk1 = torch.zeros_like(spk1_tmp)\n",
        "            # mask_spk1[self.idx1, index] = 1\n",
        "            # spk1 = spk1_tmp * mask_spk1\n",
        "            # spk1[:, index] = 1;\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)\n",
        "print(batch_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FOJTim88fhkn"
      },
      "source": [
        "Old network (if using above net, don't run the following code block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1CFB6LAJaB47"
      },
      "source": [
        "## 3. Training\n",
        "Time for training! Let's first define a couple of functions to print out test/train accuracy for each minibatch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7V0_NGKSaB48"
      },
      "source": [
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    output, _ = net(data.view(batch_size, -1))\n",
        "    # output, _ = net(data.view(batch_size, 1, 28, 28))\n",
        "    _, am = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == am). detach().cpu().numpy())\n",
        "\n",
        "    if train is True:\n",
        "        print(f\"Train Set Accuracy: {acc}\")\n",
        "    else:\n",
        "        print(f\"Test Set Accuracy: {acc}\")\n",
        "\n",
        "def train_printer():\n",
        "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\n",
        "    print_batch_accuracy(data_it, targets_it, train=True)\n",
        "    print_batch_accuracy(testdata_it, testtargets_it, train=False)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9uVWFKdXaB48"
      },
      "source": [
        "### 3.1 Optimizer & Loss\n",
        "We'll apply the softmax function to the membrane potentials of the output layer in calculating a negative log-likelihood loss.\n",
        "The Adam optimizer is used for weight updates.\n",
        "\n",
        "Accuracy is measured by counting the spikes of the output neurons. The neuron that fires the most frequently will be our predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I4BNFQkBaB48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e4ff93-043b-443e-9946-72d0fbcf1255"
      },
      "source": [
        "lr = 2e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "loss_fn = nn.NLLLoss()\n",
        "print(batch_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0enleDrOaB49"
      },
      "source": [
        "### 3.2 Training Loop\n",
        "Now just sit back, relax, and wait for convergence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgPDDt5Xs8U-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327fb938-6ffa-4a1d-8a12-ed973cb57c4b"
      },
      "source": [
        "# tmp = torch.tensor([[1, 0,0,1], [0,1, 1, 0]])\r\n",
        "# print(tmp)\r\n",
        "# tmp_index = torch.argmax(tmp, dim=1)\r\n",
        "# len = torch.arange(2)\r\n",
        "# print(len)\r\n",
        "# print(tmp_index)\r\n",
        "# mask = torch.zeros_like(tmp)\r\n",
        "# mask[len, tmp_index] = 1\r\n",
        "# print(tmp * mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 0, 0, 1],\n",
            "        [0, 1, 1, 0]])\n",
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "tensor([[1, 0, 0, 0],\n",
            "        [0, 1, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JpdYo0G6fhkp"
      },
      "source": [
        "High precision BPTT training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "P225z9fafhkq",
        "outputId": "6f10f0ab-ff2a-4fa4-cc04-5187318ce077"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    new_lr = lr * (0.85 ** epoch)\n",
        "    # lr = lr\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(6):\n",
        "    print(batch_size)\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        output, mem_rec = net(data_it.view(batch_size, -1))\n",
        "        # output, mem_rec = net(data_it.view(batch_size, 1, 28, 28)) # [28x28] or [1x28x28]?\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # BNN OPTimization\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.data.copy_(p.org)\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.org.copy_(p.data.clamp_(-1,1))\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(testdata_it.view(batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(testdata_it.view(batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "          train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "    # print(batch_size)\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # print(images.size())\n",
        "\n",
        "        # If current batch matches batch_size, just do the usual thing\n",
        "        if images.size()[0] == batch_size:\n",
        "          outputs, _ = net(images.view(batch_size, -1))\n",
        "          # outputs, _ = net(images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "        # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "        # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "        else:\n",
        "          temp_bs = batch_size\n",
        "          batch_size = images.size()[0]\n",
        "          outputs, _ = net(images.view(images.size()[0], -1))\n",
        "          # outputs, _ = net(images.view(images.size()[0], 1, 28, 28))\n",
        "          batch_size = temp_bs\n",
        "\n",
        "        _, predicted = outputs.sum(dim=0).max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "    print(f\"Test Set Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "Epoch 0, Minibatch 0\n",
            "Train Set Loss: 106.17729187011719\n",
            "Test Set Loss: 108.29342651367188\n",
            "Train Set Accuracy: 0.1328125\n",
            "Test Set Accuracy: 0.0546875\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0f16a58e9e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtargets_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_it\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_it\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# output, mem_rec = net(data_it.view(batch_size, 1, 28, 28)) # [28x28] or [1x28x28]?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_rec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e8732a2501e2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcur1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# index = torch.argmax(spk1_tmp, dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# mask_spk1 = torch.zeros_like(spk1_tmp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-9abb3cd8e52c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-9abb3cd8e52c>\u001b[0m in \u001b[0;36mfire_single\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mspk_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspike_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmask_spk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DpTsZZLmaB4-"
      },
      "source": [
        "## 4. Results\n",
        "### 4.1 Plot Training/Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Yw9hpEi7aB4-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "91156300-1752-46ca-b501-2001e6276826"
      },
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "plt.plot(loss_hist)\n",
        "plt.plot(test_loss_hist)\n",
        "plt.legend([\"Test Loss\", \"Train Loss\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAE9CAYAAACleH4eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVzVdfb48ddd2PfLqiBcUAEVEZUlSTE109S0fdo1K5umdKbdqaasmWaabzNN61S22TTza9HK9kUrc00Ec98AAQGRfUfWe39/fARFtsvlXi7LeT4ePdB7P/dzD6ZweL/P+xyV0Wg0IoQQQgghbEZt6wCEEEIIIYY6SciEEEIIIWxMEjIhhBBCCBuThEwIIYQQwsYkIRNCCCGEsDFJyIQQQgghbExr6wB6w8fHB71eb+swhBBCCCG6lZWVRXFxcYfPDeiETK/Xk5KSYuswhBBCCCG6FRsb2+lzsmUphBBCCGFjkpAJIYQQQtiYJGRCCCGEEDZmtRqypUuX8uWXX+Ln58eBAwcAWLt2LatWreLw4cMkJye32Uv929/+xltvvYVGo+HFF19kzpw51gpNCCGEEOdobGwkNzeXuro6W4cyKDg6OhIUFISdnZ3Jr7FaQrZkyRLuuecebrnlltbHoqKi+OSTT7jzzjvbXHvo0CE++OADDh48yMmTJ7n44os5duwYGo3GWuEJIYQQ4ozc3Fzc3NzQ6/WoVCpbhzOgGY1GSkpKyM3NJTQ01OTXWW3LMikpCZ1O1+axMWPGEBER0e7azz77jOuuuw4HBwdCQ0MZNWoUycnJ1gpNCCGEEOeoq6vD29tbkjELUKlUeHt793i1sV/UkOXl5TFixIjW3wcFBZGXl2fDiIQQQoihRZIxyzHnz3LA9SFbvXo1q1evBqCoqMjG0QghhBCit0pKSpg1axYAp06dQqPR4OvrC0BycjL29vZdvn7Tpk3Y29uTmJjY7rk1a9aQkpLCyy+/bPnALahfJGSBgYHk5OS0/j43N5fAwMAOr122bBnLli0Dum6wJoQQQoiBwdvbmz179gCwatUqXF1deeCBB0x+/aZNm3B1de0wIRso+sWW5cKFC/nggw+or68nMzOTtLQ04uPjbR2WECY7cqqSvPLTtg5DCCEGjdTUVKZPn87kyZOZM2cO+fn5ALz44ouMHTuW6OhorrvuOrKysnjttdf417/+RUxMDFu2bDHp/s899xxRUVFERUXx/PPPA1BTU8P8+fOZMGECUVFRfPjhhwCsXLmy9T17kij2hNVWyK6//no2bdpEcXExQUFBPPnkk+h0OpYvX05RURHz588nJiaG7777jnHjxnHttdcyduxYtFotr7zyipywFAOG0Wjk1nd2ERHgxppb5QcJIYToLaPRyPLly/nss8/w9fXlww8/5NFHH+Xtt9/mmWeeITMzEwcHB8rLy/H09OS3v/1tj1bVUlNTeeedd9i5cydGo5GEhASmT5/O8ePHGT58OF999RUAFRUVlJSU8Omnn3LkyBFUKhXl5eVW+ZytlpC9//77HT5+xRVXdPj4o48+yqOPPmqtcISwmpzS0+RX1FFV10RTswGtpl8sPAshhFme/OIgh05WWvSeY4e788Rl40y+vr6+ngMHDjB79mwAmpubGTZsGADR0dHceOONXH755Vx++eVmxbN161auuOIKXFxcALjyyivZsmULc+fO5f777+fhhx9mwYIFTJs2jaamJhwdHbnttttYsGABCxYsMOs9uyPfOYTopV1ZpQBU1zdxOL/KxtEIIcTAZzQaGTduHHv27GHPnj3s37+f77//HoCvvvqKu+++m927dxMXF0dTU5PF3jc8PJzdu3czfvx4HnvsMZ566im0Wi3JyclcffXVfPnll8ydO9di73euflHUL8RAlpJdiqOdmrpGAzszSxgf5GHrkIQQwmw9WcmyFgcHB4qKitixYwdTpkyhsbGRY8eOMWbMGHJycpgxYwZTp07lgw8+oLq6Gjc3NyorTV/VmzZtGkuWLGHlypUYjUY+/fRT3nvvPU6ePIlOp+Omm27C09OTN998k+rqampra5k3bx4XXnghYWFhVvmcJSETopd2ZZUxJcyb48U1JGeWcvs06/xjFUKIoUKtVrNu3TpWrFhBRUUFTU1N/OEPfyA8PJybbrqJiooKjEYjK1aswNPTk8suu4yrr76azz77jJdeeolp06a1ud+aNWtYv3596+9/+eUXlixZ0nqA8Pbbb2fixIl89913PPjgg6jVauzs7Hj11Vepqqpi0aJF1NXVYTQaee6556zyOauMRqPRKnfuA7GxsaSkpNg6DDGEldY0MOnPG3hobgSZRTVsPFxA6mOzUaulwaIQYuA4fPgwY8aMsXUYg0pHf6Zd5S1SQyZEL6ScqR+L0+uID9VRVttIelG1jaMSQggx0EhCJkQvpGSXYa9RMz7Qg4RQbwB2ZpbaOCohhBADjSRkQvTCrqxSooM8cLTTMELnRIC7I8mSkAkhhOghSciEMNPphmb251YQq9cByjDZ+FAdyZklDODSTCGEEDYgCZkQZtqTU06TwUh8qFfrY/GhOgoq6zlRWmvDyIQQQgw0kpAJYaaWgv7JwbrWxxJClV9LHZkQQoiekIRMCDPtyi4jwt8ND2e71sdG+bni5WzHLknIhBDCZCUlJcTExBATE0NAQACBgYGtv29oaOjytSkpKaxYsaJH76fX6ykuLu5NyBYnjWGFMEOzwcju7DIWxQxv87hKpSJOryM5SxIyIYQwlbe3N3v27AFg1apV7QaFNzU1odV2nLLExsYSGxvbJ3Fak6yQCWGGw/mVVNc3ER+qa/dcfKiO7JJaTlXU2SAyIYQYHJYsWcJvf/tbEhISeOihh0hOTmbKlClMnDiRxMREjh49CsCmTZtaB36vWrWKpUuXctFFFxEWFsaLL75o8vtlZWUxc+ZMoqOjmTVrFidOnABg7dq1REVFMWHCBJKSkgA4ePAg8fHxxMTEEB0dTVpaWq8/X1khE8IMLfVjLScsz9XSjyw5q5SFE4a3e14IIYRpcnNz2b59OxqNhsrKSrZs2YJWq2Xjxo088sgjfPzxx+1ec+TIEX766SeqqqqIiIjgrrvuws7OroO7t7V8+XIWL17M4sWLefvtt1mxYgXr16/nqaee4rvvviMwMJDy8nIAXnvtNX7/+99z44030tDQQHNzc68/V0nIhDDDruwyhns4Eujp1O65McPccHXQkpxZIgmZEGLg+WYlnNpv2XsGjIdLn+nxy6655ho0Gg0AFRUVLF68mLS0NFQqFY2NjR2+Zv78+Tg4OODg4ICfnx8FBQUEBQV1+147duzgk08+AeDmm2/moYceAuDCCy9kyZIlXHvttVx55ZUATJkyhaeffprc3FyuvPJKRo8e3ePP7XyyZSlEDxmNRlKySjtcHQPQatRMDvGSBrFCCNFLLi4urb/+05/+xIwZMzhw4ABffPEFdXUdl4U4ODi0/lqj0dDU1NSrGF577TX+8pe/kJOTw+TJkykpKeGGG27g888/x8nJiXnz5vHjjz/26j1AVsiE6LHcstMUVNYTp/fq9Jr4UB3PfneU0poGdC72fRidEEL0khkrWX2hoqKCwMBAANasWWPx+ycmJvLBBx9w880387///Y9p06YBkJGRQUJCAgkJCXzzzTfk5ORQUVFBWFgYK1as4MSJE+zbt4+ZM2f26v1lhUyIHmpZ+YrroKC/RUs/sl1y2lIIISzioYce4o9//CMTJ07s9aoXQHR0NEFBQQQFBXHffffx0ksv8c477xAdHc17773HCy+8AMCDDz7I+PHjiYqKIjExkQkTJvDRRx8RFRVFTEwMBw4c4JZbbul1PCrjAJ7xEhsbS0pKiq3DGFqMRtjxMoyeA77hto7GJv74yT6+3JfP3scvQa1WdXhNfVMz0au+56YLQvjTgrF9HKEQQvTM4cOHGTNmjK3DGFQ6+jPtKm+RFTLRM4c+g+8fg52v2joSm9mVVUZsiFenyRiAg1bDxGBPqSMTQghhEknIhOka62DD48qvs7fbNhYbKa1pIL2wutOC/nPFh3pz8GQFVXUdnwQSQgghWkhCJky38zUoz4awGVB0BGqH3upPanYZAHEmJGQJoToMxrOvEUIIITojCZkwTXURbP6HUjt20UrlsRM7bBuTDezKKsVeoyY6yKPbaycGe6JVq2TbUggxIAzgkvJ+x5w/S0nIhGk2/RWaTsMlf4HhE0HjMCS3LXdllRId5IGjnabba53ttUQFekhCJoTo9xwdHSkpKZGkzAKMRiMlJSU4Ojr26HXSh0x0r+AQpK6BuDvOnqwMih1yCdnphmYO5FVw29Qwk1+TEKrjnW1Z1DU2m5TECSGELQQFBZGbm0tRUZGtQxkUHB0dTZoOcC5JyETXjEb4/lFwcD+7VQkQkghbnoP6anBwtV18fWhvbjmNzcYuG8KeLz5Ux+ubj7Mnp5wLwrytGJ0QQpjPzs6O0NBQW4cxpMmWpeha2gbI+BGmPwzO5xSyB08BYzPkJtsutj7WMlB8cojpCVlsiA6VCtm2FEII0SVJyETnmhuV1THdSIi7ve1zI+JBpYbsoVPYn5xVRoS/G57Opo9C8nC2IzLAXRIyIYQQXZKETHQudQ0UH4NL/gza85IQBzcYNmHInLRsNhjZnV1GbA+2K1skhOpIzS6jsdlghciEEEIMBpKQiY6dLoOf/gr6aRAxr+NrghMhdxc01fdtbDZw5FQl1fVNJvUfO198qI7TjcqBACGEEKIjkpCJjm3+h5KUzfkrqDoZERQyBZrq4OSevo3NBlKylOau5qyQtSRxsm0phBCiM1ZLyJYuXYqfnx9RUVGtj5WWljJ79mxGjx7N7NmzKStTvslt2rQJDw8PYmJiiImJ4amnnrJWWMIUJRmw83WYeBMMi+78uuApyscTg7/9xa6sUoZ7OBLk5dzj1/q6ORDm6yIJmRBCiE5ZLSFbsmQJ3377bZvHnnnmGWbNmkVaWhqzZs3imWeeaX1u2rRp7Nmzhz179vD4449bKyxhig2Pg8YeZv6p6+tcfMAnYtD3IzMajezKKjVpfmVnEkJ1JGeV0myQpotCCCHas1pClpSUhE7X9hvYZ599xuLFiwFYvHgx69evt9bbC3NlboEjX8K0e8HNv/vrQ6bAiZ1gaLZ+bDaSW3aagsr6HvUfO198qI6quiaOnqqyYGRCCCEGiz6tISsoKGDYsGEABAQEUFBQ0Prcjh07mDBhApdeeikHDx7s9B6rV68mNjaW2NhY6ShsaYZm+O4R8BgBU+4x7TXBiVBfAYWHrBubDe0603+sNytk8aFKU9jkzBKLxCSEEGJwsVlRv0qlQnWmWHzSpElkZ2ezd+9eli9fzuWXX97p65YtW0ZKSgopKSn4+vr2VbhDw9734dQ+uHgV2DmZ9pqQROXjIN623JVVhpujlnB/N7PvEejpRKCnE8lZUkcmhBCivT5NyPz9/cnPzwcgPz8fPz8/ANzd3XF1VcbvzJs3j8bGRoqLi/syNFFfDT88BUFxEHWV6a/zHKGsqA3ihCwlq5TYEC806k5Om5ooPlRHcmapDO8VQgjRTp8mZAsXLuTdd98F4N1332XRokUAnDp1qvWbVHJyMgaDAW9vmfvXp7Y9D9UFMOdvnbe56EzwFKVB7CBMNMpqGkgrrO7VdmWL+FAdxdUNHC+usUBkQgghBhOrJWTXX389U6ZM4ejRowQFBfHWW2+xcuVKNmzYwOjRo9m4cSMrVyrDqtetW0dUVBQTJkxgxYoVfPDBB63bmaIPVOTC9peUlbERcT1/fUiiksyVHrd8bDaWkq20ZjGnIez54kOVe+yS9hdCCCHOo7XWjd9///0OH//hhx/aPXbPPfdwzz0mFpELy9v4pPLx4lXmvf7cOjLvkZaIqN9IySrFXqMmOsij1/cK83HBx9We5MxSrosPtkB0QgghBgvp1D/U5abC/o9gyt3gaWaS4BMOzt6Dcq7lrqxSxgd54Gin6fW9VCoV8aE6dsoKmRBCiPNIQjaUGY3w3R/B1R+m3mv+fVQqpY4se5vlYusH6hqb2Z9XYZHtyhbxeh155afJLau12D2FEEIMfJKQDWUHP4GcnTDzMXAwv6UDoGxblmVBZb5FQusP9uSU09hs7FVD2PO19CPbJe0vhBBCnEMSsqGqsQ42rAL/8RBzY+/vNwjnWqacSZomh1guIYsIcMPdUStzLYUQQrQhCdlQ9cu/oeIEzHka1L2vjyIgGuxdB1U/sl1ZZYT7u+LpbG+xe2rUKuL0UkcmhBCiLUnIhqLqQtjyHETMg7DplrmnRgsj4iF7cBT2NxuM7M4us0j/sfPFh+o4XlRDUVW9xe8thBBiYJKErAtNzQZKqusHX2f1H/8CTadh9p8te9/gRGWmZe3AX/05cqqSqvom4q2UkIHUkQkhhDjLan3IBoOMohrmPL8ZJzsNgV7KLMKWj0Feyn+Bns74uTmg7uVYnT5z6gD8+h4k/BZ8Rln23iGJgFE5KBBxqWXv3cdSspSGsLEWLOhvERXogZOdhuTMUuaNH2bx+wshhBh4JCHrgpeLHY8vGNvapiCv/DT7csspq21sc52dRsUwj7OJ2rnJW5CnM8M8HbHT9IPFSKMRvnsEHD1g+kOWv3/gZNDYK3VkAzwh25VVyjAPRwI9TRyy3gN2GjWTQ7ykjmwIamgyUFbbgL+7o61DEUL0M5KQdcHPzZGlU0PbPV5T38TJ8tPklp0mt/w0eWWnySs/TV5ZLT8fK6LwvNogtQr83R3brLAFejkRonMhIUzXd8nase8g82eY+3dwsvzKD3aOMHzSgG8QazQa2ZVVSnyot9VGeMWH6vjXxmNU1Dbi4WxnlfcQ/c872zJ58Yc0dj12Mc728uVXCHGWfEUwg4uDltH+boz277h3V31TM/nldWdX1s5J3FKzy/hyXz7NBqUubWKwJy9eN5EROmfrBt3cCN8/Bt6jIe42671PSCJsfxEaasHeyp+TleSWnaagsp54K2xXtojT6zAaISW7lFlj/K32PqJ/2ZdbQU1DM3tOlJM4ysfW4Qgh+hFJyKzAQatB7+OC3selw+ebmg0UVNWzPb2Yp744xLwXt/DMldHMj7ZiPdGut6AkDa7/EDRWXJEJSYStz0HuLsud4OxjLcX21jhh2WJisCd2GhXJWZKQDSXphdWA0lJFEjIhxLn6QWHT0KPVqAn0dOKa2BF8tWIaI31dufv/7eaPn+zjdEOz5d+wthQ2/Q3CLoLwOZa//7lGxAOqAb1tuSurDDdHLeGdrIBagqOdhglBntIgdghpajaQWVwDKCujQghxLknIbCzY25m1v53Cb6eP5P3kHBa+vJUjpyot+yY//x/UV8KcvypzJ63J0QMCxg/oBrEpWaVMDvFCY+WTs/GhOvbnVlDb0GTV9xH9Q27ZaRqaDbg7atmdXUZTs8HWIQkh+hFJyPoBO42alZdG8t5t8ZTVNrLo5W2890u2ZfqfFafDrjdg4s3gP6739zNFSKKyZdnc2P21/UxZTQNphdUWHSjemfhQHU0GI7+eKLf6ewnba9muvHJSEDUNzRw5VWXjiIQQ/YkkZP3ItNG+fPP7aSSEefOn9Qe467+7Ka9t6N1NN/wJtE7KAPG+EjwFGmshf2+PX5pXfpq6Rits25ooNVvpP9YXCdnkEC/UKqT9xRCRXqQkZNfFjwCkMbAQoi1JyPoZXzcH1iyJ45F5kWw8XMC8F7aY/4X7+M9w9GuYdh+4+lk20K6EJCofe7htWV3fxNx/beaBtT1P5CxlV1Yp9ho10UEeVn8vN0c7xg33IDmzxOrvJWwvvbAaXzcHIgPcCfR0am0+LIQQIAlZv6RWq1iWNJKP70pEq1Hzm9d38NIPaa2tMkxiaFaawHoGwwW/s16wHXH1A+9RPU7Ivt6XT1V9E1/uy7dZsfuurFLGB3ngaGeBgesmiA/V8euJcuqbbLcqKPpGemE1o3xdAWUCxK6s0sE3lk0IYTZJyPqxCSM8+WrFVC6bMJx/bjjGjW/+wqmKOtNe/Ot/oeAAXPyk0rC1rwVPUU5aGkwvXF6XmkuojwvDPRx58ouDPUtALaCusZn9eRVWGZfUmfhQHfVNBvbnVvTZe4q+ZzQaySisZqSf0gonVq+jsKqenNLTNo5MCNFfSELWz7k52vH8b2L4xzUT2JdbwaUvbOaHwwVdv6i2VBkgPiIBxl3RN4GeL+RCqCuHoiMmXZ5VXENyVinXxo5g5bwxHDxZydqUHCsH2dbenHIam43EhVi/fqxFS62a1JENboVV9VTVN7WukMWdSfqljkwI0UISsgFApVJx9eQgvlg+lWEeTtz2bgqrPj/Y8TaXwQCf3qkkQ/OetX6bi86ETFE+Zm8z6fJPdueiVsEVEwO5LHoYsSFePPvdUSrr+u6kZkq29QaKd0bnYk+4v6v0IxvkMs6csBzlp/S2C/dzw81RK/3IhBCtJCEbQEb6uvLp3YnceqGeNduzuOKV7WScObnVavsLkPa90nNs2ATbBArgGQJuw01qEGswGPl4dx7TRvsS4OGISqXiicvGUVrbwEs/pPVBsIrkzFLC/V3xdLbv+Yuzt0PhYbPeNz5UR6r0pRrUWk5YjvJTVsjUahWxIV7sksJ+IcQZkpANMA5aDU9cNo63FseSX3Gay17aytqUHKU4OHsH/PBnGHs5xN1u20BVKuW0ZfYO6KZwecfxEvLKT3P15KDWx8YHeXDt5BG8sy2rfdJpBc0GI7uzy8wbl1RdCP+9Cj64wazea/Gh3lTXN3E4X/pSDVbphdW4Omjxd3dofSxWryO9sJrSml62thFCDAqSkA1Qs8b4883vk4gO8uDBdft49H+bMKxdAl4hsPAl221VnitkClSdhLKsLi9bl5qLm6OW2WPbznR8YE4EjnYanv7KvJWnnjh6qoqq+qbW2p4e2fJPpe9a6XFIXdPjl8e31pFJ+4vBKr2wmpF+rqjO+XfZUj/Y0vtOCDG0SUI2gAV4OPK/2y/g/otHMefY4zRWl3A06WVwdLd1aIrgM/3Iuti2rKpr5JsD+SycMLxdqwlfNwdWzBrFj0cK+elooTUjba3lie1pQX95DqS8DZNugZCp8PPfob5nK10BHo4E65yljmwQO7flRYvoIA/sNWpSpLBfCIEkZAOeRq1iuf3nTFfv4wXtbcz/qILVmzMw9HHLiA75RoKjZ5f9yL7en09do6HNduW5liSGEurjwp+/PESjFWusdmWVMczDkSAvp569cPP/KR+nPwyzn4SaItj+co/fPz5UJ32pBqnKukYKq+pb68daONppGB/kIScthRCAJGQDX+Zm+OmvMP4a7rz3z1w8xp+/fn2EW9fs6v3Ypd5Sq8/UkXWekK1LzWWUnysxIzw7fN5eq+ax+WM4XlTDf3ZkWyVMo9HIrsxSYvW6NltK3SrJgF//B7G3gUcQBMXC2EWw/SWlrqwH4kN1lNU2ts47FINHy//Tkb4u7Z6L1XuxP6/CpuPChBD9gyRkA1l1IXx8O+hGwoLn8XCx59WbJvGXy6PYll7McxuO2TpCpUFsaQZUte+dllVcw66sMq6eHNRlIjQz0o+kcF+e33iMkup6i4eYW3aaU5V1Pa8f++mvoHVQRlO1mPUENNUpW5c9kBAq/cgGq/TCticszxUXoqOx2cjeHBkwL8RQJwnZQGVoho9vg7pKuPZdcFC+2KtUKm66IIQrJgbyUUqO7U9whXReR/bxOb3HuqJSqXh8wRhqG5r5pxWSTLPqx04dgAMfwwV3tZ0T6j0SJi9RivtLMky+XbDOGX93B6kjG4Qyiqqx16gJ1jm3e25yiPJDQIoU9gsx5ElCNlD9/H/KduW8Z8F/XLun70gKo67RwHtW2uYz2bAJYOfcbtuy2WDk49RcksJ98XfvfrTTKD83bpkSwvvJJzh40rJjhnZlleHmoCUiwM30F/30NDi4Q+Ly9s9dtBI0DvDDUybfTqVSER/qTXKm1JENNhmF1eh9nNFq2n+59XKxZ7Sfq9SRCSGsl5AtXboUPz8/oqKiWh8rLS1l9uzZjB49mtmzZ1NWpvxUaDQaWbFiBaNGjSI6Oprdu3dbK6zBIeMnZUtswvUw8aYOLwn3d2NGhC//2ZFl2/oUjR0ExcGJtgnZjowSTlbUdVrM35E/zArH08mOp744ZNGkJSWrlMl6LzRqE+vHclPg6Ndw4XJw6mCb09VPSdQOrYfcVJPjiA/VcaqyTuYbDjLphdUdble2iNUrjYH7enarEKJ/sVpCtmTJEr799ts2jz3zzDPMmjWLtLQ0Zs2axTPPPAPAN998Q1paGmlpaaxevZq77rrLWmENfFWn4JM7wDcC5v+zy35jy5JGUlLTwMe7c/swwA6EJCpbfHVnV7bWpebg7qjl4jH+XbywLQ9nO+6/JIKdmaV8c+CURUIrq2ngWEF1a08ok/z4Z3D2gYQu/p4m3gMuvrDh8W4b47Y4W0cm/cgGi7rGZk6U1rZreXGuOL0XVXVNHCuQxsBCDGVWS8iSkpLQ6dp+k/vss89YvHgxAIsXL2b9+vWtj99yyy2oVCouuOACysvLyc/Pt1ZoA1dzE6y7DRpq4Jp3wb79qa1zXRCmIzrIgze3ZNr2p++QRMAIJ3YCShuAbw+eYmFM+95j3bk+PpjIADee/uqwRVb+WppyxoaYWNCfuRmOb4Jp97fW7XXIwU1phZG9FdI2mHTrUb6ueDnbSR3ZIJJVUoPBCCO7WCFr+WFA+pEJMbT1aQ1ZQUEBw4YNAyAgIICCAuXkXV5eHiNGjGi9LigoiLy8vL4MbWDY9FflG/yCf4FfZLeXq1Qq7pgWRmZxDRsOtT/l2GcCY0Ft17pt+fU+pffYNZNHdPPC9jRqFY9fNpa88tO8ueV4r0PblV2KnUbFhE7abrRhNCqjqdwDIXZp99dPWgxeobDxCeUQRjfUahVxeh3J8o150OjqhGWLIC8n/N0dZK6lEEOczYr6VSpVz3o+nbF69WpiY2OJjY2lqKjICpH1U2kblRE9E2+GCdeZ/LJLowII8nLiDQskL2azd4bhMcpcS5TeY6P9XIkO8jDrdokjfbg0KoBXfsrgVEVdr0JLySojOsjTtJW6tGr6EUgAACAASURBVO8hNxmmPwR23R9EQGsPsx6HwkOw9wOT4okP1ZFdUtvrz0v0D+mF1ahUEObTeUKmUqmI1etkhUyIIa5PEzJ/f//Wrcj8/Hz8/JR2AYGBgeTk5LRel5ubS2Bgx60Qli1bRkpKCikpKfj6+lo/6P6gIk+pG/Mbp5yq7AGtRs3tU0NJzS4jNduGX/BDEiEvlaxTxaRkd997rDuPzBtDs9HI3789YvY96hqb2ZdbTqwp/ccMBmV1zCsUYm40/U3GXQHDJymnMhu7L9ZPCPUGkFWyQSK9sJpATyec7LtO+ONCvDhZUUdeuRzoEGKo6tOEbOHChbz77rsAvPvuuyxatKj18f/85z8YjUZ++eUXPDw8Wrc2h7zmRli3FJoblH5jdj0c7QNcGzcCDyc7Xv/ZhqtkwYlgaGTH5u9N6j3WnRE6Z5ZNC+PTX/PMHs68N6ecxmYjcab0Hzu0Hgr2w4xHlJOjplKplJFKlXmQvLrby8cMc8PFXkOyFPYPChlFNV1uV7aIlToyIYY8qyVk119/PVOmTOHo0aMEBQXx1ltvsXLlSjZs2MDo0aPZuHEjK1euBGDevHmEhYUxatQo7rjjDv79739bK6yB58c/Q84vcNkL4DParFs422u5+YIQNhwu4HiRjUbzBCdgREXl0c1MD/fFz4TeY92566KR+Ls78NQXB82a3dnSjHNydwX9zU1KV37fMRB1Vc8DDU2CUbOVLefarr/hajVqJut1Utg/CDQbjBwvaj9UvCORAW64OmilH5kQQ5jWWjd+//33O3z8hx9+aPeYSqXilVdesVYoA9fRb2HbC0oB+fire3WrxYl6Vm85zptbM/nrFeMtFGAPOHlR4xnBmJIDBJlRzN8RFwctKy+N5N4P9/LJr3k96mkGsCurlNF+rni52Hd94b4PoCQNfvM/UPfsVGiri1fBa1Nh67/gkj93eWlCqI5nvztKWU1D97GJfiuv7DT1TQaTVsi0GjUTgz1JkcJ+IYYs6dTfX5WfgE/vhIBomPO3Xt/O182BqyYFsi41l2IrzIM0xW4imaxJY1ZED3p+dWPRhEAmBnvy92+PUF3fZPLrmg1GUrPLiAvtJpametj0d6UOLHK++YEGRCmHMXa+DuU5XV4afyYmWS0Z2NKLlL5ipiRkoLS/OFpQRUVtozXDEkL0U5KQ9UdNDbD2VqVVwjVrTDvRZ4Lbp4XR0GTgP9uzLHK/nqisa+STkmBcqMOx+KDF7qtWq3jisnEUVdXzyk/pJr/u6Kkqquqauh8ovvs/UHECZj7WZRNek8x4VPn401+7vCw6yAN7rVq2LQe4lpYXI03YsgSI1XthNMLuE7JKJsRQJAlZf7RxFeSlwKKXlWHVFjLS15WLx/jzn1+yqW0wfTXJEr7al8/2xgjlN+fNteytmBGeXDUpiLe2ZJJdUmPSa0waKN5QC5ufhZCpMHJm7wP1HAEJy2Dv+1DQeVLqoNUwcYSnnLQc4NILq/F2sTd52zlmhCdatUpWRoUYoiQh628Ofwm/vALxy2Dc5Ra//Z3TwyivbWRdat+OU1qXmoun/wiMXqFwYofF7//w3AjsNCqe/uqwSdfvyiojwN2RIK8uTq0mr4bqApj1p96vjrWYeh84uitJdxcSQnUcyKvo0Tas6F/SC6u77NB/Pmd7LeMCPaSOTIghShKy/qQsC9b/DoZPhEv+YpW3iA3xYmKwZ5+OU8ooqia1pfdYSKKyQmbB4eAAfu6O3D1zFN8fKmBrWnGX1xqNRnZllhKr9+q8F1pdBWx7XjkdGXyB5QJ11ilJWdr3kLml08viQ70xGDG7pYewLaPR2O1Q8Y7EhXixJ7ec+qbejwUTQgwskpD1F031sHaJ8utr1oDWwSpvo1KpuDMpjBOltXxroQHd3fk4NReNWsXlMYFKg9jTpVB01OLvs/TCUEbonHjqy4M0NRs6vS6v/DSnKutai+c7tOMVOF2m1I5ZWsKdyvilLgaPTwpRtq+kH9nAVFzdQGVdk0ktL84Vq9fR0GTgQF6FlSITQvRXkpD1F9//CU7+Cpf/G7z0Vn2r2WMD0Hs7s3pzBkYLr1Sdr9lg5JPdeWd7jwVPUZ44Ydk6MgBHOw2PzhvLsYJq/l/yiU6va6nR6bR+rKZEScjGLlJGPlmanZPSYPbkbqXhbAec7bVEBXpIYf8AZcoMy460TI2QuZZCDD2SkPUHB9dD8utwwd0wZoHV306jVnHbtDD25lZY/Rv+tvRiTlXWne0RpgsDV//WuZaWNmecP4kjvfnn98coq2no8JpdWWW4OWiJCHDrJOh/QWPt2VOR1jDheqXR7A9PKdMYOpAQqmNvTgV1jbJ9NdCkF5mXkPm4OhDm4yId+4UYgiQhs7WSDPh8OQTGKs1D+8g1k4PQudizerN1xymtS83F09mOWWOUuaWoVMq2pYVPWrZQqVQ8ftlYquoaeX7jsQ6vSckqZVKIFxp1B/VjlfmQ/AZEXwe+EVaJEVAazF68CkqPQ+qaDi+JD9XR0GxgT0659eIQVpFRWI2LvYZhHj1vWROr9yIlu8ys6RNCiIFLEjJbaqyDtYtBpYZr3gFt33Vld7TTcMuUEH44UkhaQZVV3qPidCPfHTzFognDcdCe0+E+OBEqc5Xmt1YQGeDOjQkh/HfnCY6eavu5ldc2cKyguvP+Y5ufVfq/XfSwVWJrI3wOhFwIP/8d6tv/P4gN0aFSIduWA1DLCctOD410IU6vo7y2kQxbjTkTQtiEJGS2YjTCtyvh1H644nXwDO7zEG6+IAQHrZo3tlhnleyrffnUNxm4+vxRSSFn6sistG0JcN/scFwdtDz15cE2dXItpxbj9B3Uj5Vmwu53YdItVq/jA84MHn8KaoqUmrXzeDjbEeHvJgnZAJReWG1yQ9jztfzdlDoyIYYWScj6mtEIR76G15Mg9R1IXAERc20SirerA9fEBrH+15MUVtZZ/P5rU3OI8HcjKtC97RN+Y8HRA7K3Wfw9W3i52HPvxaPZll7ChkMFrY8nZ5Vip1ExYYRn+xf9/HdQayHpQavF1U5QLIxZCNtehOrCdk8nhOpIzS6jsYtTo6J/qapr5FRlXY/rx1qEeDvj4+ogdWRCDDGSkPUVo1EZFr76IvjgemWL6vJX4eInbRrW7VPDaDQYWGPhcUrphdX8eqJc6T12/raNWgMjLrBKg9hz3XhBCKP9XHn668OtfZ1SssoYH+iBo915Q8KLjsK+DyH+DnAfZtW42pn1BDTVKQnheeJDvTnd2CxtEAaQ40XKtAhzV8hUKhVxei92ZUtCJsRQIgmZtRmNcOw7eGMGvP8bqCuHRf+Ge1Ig5gZQ2/Z/gd7HhbnjAvjvL9kW7Qr/8W6l99iiicM7viBkChQfg5qum7j2hp1GzeOXjSW7pJZ3tmVR19jMvtzyjrcrf3oa7FzgwnutFk+nfEbB5CVKcX9JRpun4kJb2iDIN+eBwtyWF+eK1evIKT3NqQrLr1wLIfonScisxWiEtA3w5iz4f9dCbQksfFlJxCbeCBqtrSNsdUdSGJV1TXy4K8ci91N6j+UyI8IXP7dOTpmFXKh8tPIq2bTRvlw8xp+Xfkjjh8OFNDYb2ydkJ/fAoc9gyu/Axduq8XRq+sOgcVDaYJzDz82RMF8X3t2ezfYM6yWvwnLSi6rRqlWEeDubfY+WQycpskomxJAhCZmlGY2QvhHevBj+dzVUF8FlL8Ly3TDpZtDY2TrCdiYFexGn9+LtrZlddrg31db0Ygoq68/2HuvIsBjQOlmt/cW5Hps/hoZmAys/3gfA5JDzTlj++Bdw8oIpd1s9lk65+UPiPUqj2NzUNk89e/UEtBoVN7yxk4fW7aW8tuP+aqJ/SC+sRu/jgp3G/C+vY4e542yvkbmWQgwhkpBZitEIGT/CW5fAf69ShlIveB6Wp8Lkxf0yETvXsqSR5JWf5qv9+b2+17rUXLyc7ZgZ6d/5RVp7paC9DxIyvY8LS6eGUlXfxGg/V7xczmkvkr0D0jfAhX9QDhrYUuJycPZpN1JpcogX3/4+id9OH8nHu/O4+Lmf+WLvSatPWRDmySis7vHIpPNpNWomBnvKVrUQQ4gkZL1lNMLxTfD2XHjvCqjMg/nPKStisbf2aW+x3pgV6UeYrwurNx/v1Tf61t5jMYHYa7v56xU8BU7t67AHl6XdM2MUwzwcSQr3Pfug0Qg//lmZHBC/zOoxdMvBTdm6zN6qbHefw8lew8pLI/ns7gsZ5uHE8vd/5bZ3U8grP22jYEVHGpoMZJfW9qp+rEVsiI7D+ZVU1XU8yUEIMbhIQtYbmZvhnXnwn0VKk9N5/4AVv0LcbQMmEWuhVqu4Y1oYB09Wsj3D/IHWX+w9SUOToevtyhYhiWA0QM5Os9/PVG6Odmy8bzp/vDTy7IMZPyqtN5IeBHvz630savIS8AqFjU8oDWrPExXowae/S+Sx+WPYkVHCJc/9zDvbMmmWru79QlZJDc0GIyP9XHp9rzi9DoMRfj0hkxqEGAokITNH1lZ4Zz68exmUZcKlzyqJWPwdoHWwdXRmu2JiID6uDr0ap7QuNZfIADfGDXfv/uKgOFBprNog9lwuDlq0LXU9LatjHsEwaXGfvL9JtPYw63EoPKS04ejoEo2a26eF8f29SUzW63jyi0Nc9ep2jpyq7ONgxflaT1j6djIntQdigj3RqFXSj0yIIUISsp7I2gZrFsCa+VCSDpf+H6zYAwnLwK7nM+v6G0c7DUsSQ/j5WJFZ39zTC6vYk9NJ77GOOLjCsAlWP2nZoSNfwslflRFJ/W01c+zlMHwi/Pi0Ml6rEyN0zrx7axzP/yaGE6W1LHhxK//47qgMI7ehjDMJmSVWyFwdtIwd5i4d+4UYIiQhM0X2DmU1bM08pXfW3Gfg93sg4c5BkYid66YLQnCy05i1SrYuNQ+tWsXlEwNNf1FIIuSmQFN9j9/PbIZmJdnxHq0MEe9v1GplpFJlLiS/3uWlKpXy573xvuksjBnOyz+lM++FLfxyvItt59pS5e906hr49o9w4GPLxj+EpRdVE+jphLO9ZdraxOq9+DVHJjUIMRT0n2ZY/VFxOnx9v1K07+IHc/4Kk2/tP/VGVuDpbM9v4kbw31+yeXBOBMM8nEx6XbPByKe/5nJRhB8+rj3Ytg1JhB0vQ97uszMure3Ax1B0GK5+p1/1g2sjNAlGzYYt/1Rmazp1Mgz9DJ2LPc9dG8MVEwN55NP9XLd6B7fHuPCHCQZcq45D0RFlGkHRUag5b0STkw7GLOq/fxYDSMtQcUuJ0+t4Z1sWB09WEtPRuC8hxKAhX4G7Yu+idE6/5C8Qe9ugTsTOddvUUP6zI4t3tmXxyLwxJr1mS1oRBZX1PLnQhGL+cwWfScJObO+bhKy5UenK7z9e2Rrszy5eBa9NhS3PwSV/7vgaoxEqcs8kW0eYVnyUTbojNNQfwelIJRw5c5mDOyrfCAi/BHwiwDcSfCMgLwXWLVUOVugv7KvPbFAyGIxkFFWTEGq55sKxZ3rmpWSVSkImxCAnCVlX3IfB7/cqsxeHkBE6Z+aNH8b/23mCe2aOwt2x+x5qZ3uP+fXszZx14DtG6Uc27X4zI+6BX/8LZVlww0c2H1vVrYAomHAd7HxdOblraG5NvCg6CsVHoegYNNacfY2zDxrfCJwmXs1JuxBeOaBhQ5EX0fpwnrp8PMM9z1vxdNYpEwKOfCUJWS/llZ+mrtFgkZYXLfzcHQnxdmZXVim3Twuz2H2FEP2PJGTdGWLJWIs7k0by5b58Pkg+wbKkkV1eW1HbyPeHCrghPrj73mMdCZkC+9cpCYc1/7wb6+Dn/4OgeBh9ifXex5JmPKJssb4woe3jbsOVFa5JNysffSOVla9zRj8NB5682IB+Wxb/3HCU2c/9zENzI7npghA06jOHLhzcIOwiOPIFzHkaTDmMITqUXtT7GZYdiQ3RseloIUaj0bTDMkKIAUkSMtGh8UEeTAnz5u2tWSxJDO0y0fp8Xw96j3UkOBFS3oaCA8qpS2tJeQuqTsKVrw+cxMMzGC5/FfL3nNlmjASf0SZPFdBq1NyRFMaccQE8un4/T3x+kPV78njmymgiAs60ZoicD2nfKX/+AeOt+MkMbq0nLH17f8LyXHF6Lz7enUtmcQ1hvZwAIITov/r5no2wpWVJYZyqrOOLvSe7vK5Hvcc60lI7Zo0xSo11ygrTe1fAd48qq0GhSZZ/H2saf7VSxzjxJmXclBkjnoK9nfnP0nieu3YCWcU1LHhpC//8/kyLjIhLAZWybSnMll5YjZezHd49OdRigli9DkDmWgoxyElCJjp1UYQv4f6uvLGl83FKaQVV7M0p55rYEeZvp3gEKStBlkzI8vfC1w/CPyOUovXidLhopXKycohSqVRcOSmIjfdNZ0H0cF76MZ15L25hS74K44gEpTebMFtGUbXFtytBWXHzcraTuZZCDHKSkIlOqVTKOKUjp6rYnFbc4TXrdueiVatYFDO8d28WnKg0iO3NwOzaUqUA/rWp8HoSpL4Lo2fDLZ8phzMuWqkUsQ9x3q4O/Os3Mby7NJ6GJgM3v5XM2yVj4dR+GkuybB3egJVeaJ2ETKVSEavXkZLdzQrZ0W/g1anQUGvxGIQQ1meThOyFF14gKiqKcePG8fzzzwOwatUqAgMDiYmJISYmhq+//toWoYnzLIoJxN/dgdWbM9o919Rs4NPdecyI7GHvsY6EJEJNkTIBoScMzZD+A6y9VVkN++YhZRzTvH/AA0fhqjeVbcr+fqLSBqaH+7Lxvuk8c+V4flLFA/DvV1/gzS3Hqa5vsnF0A0tJdT1ltY2MtFKNV5zei8ziGoqqumigvPM1KNjfJ7NhhRCW1+dF/QcOHOCNN94gOTkZe3t75s6dy4IFCwC49957eeCBB/o6JNEFe62aJYmh/P3bIxzIqyAq8Gz90pb0Ygqr6s0v5j9XSKLyMXu7UrTendJM2PP/lP8qc5XmprG3wcQbpTC9BxztNFwXH8y1sSOofuE5Lj69i/lfHeaFH9K4MSGEWy/U4+8+uKZRWEPrDEsrrJDB2Tqy1OxS5kYNa39BVQFkblZ+nbUVRs6wShxCCOvp82WDw4cPk5CQgLOzM1qtlunTp/PJJ5/0dRiiB25ICMbFXsMbW9qOU1qXkovOxZ4ZET3sPdYR71Hg4tv1XMuGWtj7oTJP9MUY2PIP8BsD17wL9x+BS5+RZMxMarUK1wmLGNd4kC9uG0NSuC+rN2cw9e8/8sDavRw9VWXrEPs1a7W8aBE13AMHrbrzuZYHPwWjAdyGKQmZEGLA6fOELCoqii1btlBSUkJtbS1ff/01OTk5ALz88stER0ezdOlSysrkRFF/4eFkx/XxwXy5L5/cMqU+pby2gQ2HClgUM9y83mPnU6mUrv3Z29o+bjRCXip88QdlS/LTZVCRAzMfgz8cgJvWwbjLQWvZk21DUuR8MBoYX72DV26YxKYHZnBjQghf7ctnzvObWfx2MtvSizs94DGUpRdW42SnYbiJo8Z6yl6rJmaEJymdFfbvX6v8MBL9G+XfS0NNx9cJMYDtyy2nvLbB1mFYjUnfSWtqajAYlOG2x44d4/PPP6exsdGsNxwzZgwPP/wwl1xyCXPnziUmJgaNRsNdd91FRkYGe/bsYdiwYdx/f8dd21evXk1sbCyxsbEUFRWZFYPouaVTQ1EBb2/NAuCLvSdpaO5F77GOhCRC+QmoyIOaYtjxCryaCG/MhL0fKAnDkq9g+a+Q9CB49GCIuejesBhwD2xtfxHs7cyqhePY8ceZPHBJOAdPVnLjmztZ8NJWPtuTJwOvz5FeWE2YrwtqtfX628XpdRw4WUltw3n1faWZygis8deAfhoYGiEn2WpxCGELVXWNXP3qDv69qX0982BhUkKWlJREXV0deXl5XHLJJbz33nssWbLE7De97bbbSE1NZfPmzXh5eREeHo6/vz8ajQa1Ws0dd9xBcnLHX1CWLVtGSkoKKSkp+Pr6mh2D6Jnhnk4siB7GB7tOUFHbyLrUXMYOc2fc8J73xOpUy1zL969TVsO+e0SZJ3rZC/DAMbjiNdBPlQJ9a1GplKQ348c2J/U8ne25Z+Zotj48g79fNZ66xmZ+/8EeLnp2kxwAOON4UY3VtitbxOq9aDYY2XOivO0TB9YpH6OuguAE5VBL1harxiJEX/vleCkNzQYOnqywdShWY9J3NqPRiLOzM5988gm/+93vWLt2LQcPHjT7TQsLCwE4ceIEn3zyCTfccAP5+fmtz3/66adERUWZfX9hHcuSRlLb0MyqLw6yN7fCsqtjoGy5uA2Dqny44C743U64fSNMXgKOZjadFT0TuQCaTkPGD+2ecrTT8Ju4YDbcO523l8QS5OXEX746zJS//cDfvjnMqYo6GwRsezX1TeSVn2aUlbvoTwrxQqWibR2Z0Qj71iptYzyClFFYgZOkjkwMOlvTlB2xwVzPatIpS6PRyI4dO/jf//7HW2+9BUBzc7PZb3rVVVdRUlKCnZ0dr7zyCp6enixfvpw9e/agUqnQ6/W8/vrrZt9fWMfY4e5MG+3Dp7/mWab32PnUGrgnRakH03Q/0FxYQUgiOHoq25ZjLuvwErVaxcxIf2ZG+rM3p5w3thznjc3HeXtrJgsnBHJHUiiRAUMngT5epNRrWXuFzN3RjsgAd1Kyz6kjKzigDJmf/9zZx/RTYftLSh2ZvWXHOAlhK1vSlV6YxdUNFFfX977VUj9kUkL2/PPP87e//Y0rrriCcePGcfz4cWbMMP9Y9ZYt7ZfT33vvPbPvJ/rOsqQwtqQVMzPSz+IjYgBwkFl9NqWxg/C5SpPR5ibQdP0lYsIIT16+YRI5pbW8tTWTj1Jy+Hh3LknhvtyZFEbiSO9BPxA7vUj5id3aCRmcmWuZmktTswGtRg3714FaC2MvP3uRfips/ZfSj2zkTKvHJIS1nSw/zfGiGmZE+PLT0SKOnarCZ9TgS8hM2rKcPn06n3/+OQ8//DAGgwEfHx9efPFFa8cm+qGpo3y4b3Y4984Ot3Uowloi50NdOZwwfZTVCJ1yAGD7ypk8OCeCw/nKAYDff7DHioH2D+mF1WjUKkK8rb8aFavXUdPQzJFTVWAwKHNaR84EF++zF4244EwdmWxbisFh65lJMbdNDQNQ/v4PQiYlZDfccAOVlZXU1NQQFRXF2LFjefbZZ60dm+iHVCoVK2aNZsywobMlNeSMmgVaR7OGjXs623P3jFFsfXgG18WN4Mt9J6moNe9E9kCRXlhNiLezZdq/dCNO7wWgzLXM2am0gBl/TduLHFyVOrJMKewXg8OW9GJ83Ry4cJQ3Ohd7jhUM4YTs0KFDuLu7s379ei699FIyMzNli1GIwcreRVl1OfKV2bNFHbQarp4chMEIW9M7noM6WKQXVlu9oL/FMA8nAj2dSMkqU05Xap0gYl77C/VT4eRuqK/uk7iEsBaDwcj29GKmjvJBpVIR4e82tFfIGhsbaWxsZP369SxcuBA7O7tBXxcixJAWOV9Zfcnfa/YtYkZ44uaoZfOxwdsvsLHZQHZJLSP7oH6sRZzei92ZhRgPfgqR8zquu9RPA0OTzLUUA97hU5WU1DQwdZQPABEBbhwrqMJgGHwNqk1KyO688070ej01NTUkJSWRnZ2Nu7tsWQkxaIXPBZXarG3LFlqNmqmjfNicVjRou/tnl9TSZDD22QoZKHVkEbWpqGpLIOrqji8akaAU+0sdmRjgWurHpo4+m5DVNjSTV37almFZhUkJ2YoVK8jLy+Prr79GpVIREhLCTz/9ZO3YhBC24uKjNOrtRUIGkBTuS35FHWmFg3PrzNpDxTsSp9exULOdBjt3GHVxxxc5uMJw6UcmBr6t6cWE+7vi7+4IKAkZDM7CfpMSsoqKCu67777WkUX3338/NTUyK02IQS1yPhQehNLj3V/biaRwZZrGYN22zDgzVLwvtyxHe6mZo0lhj9t00Np3fqHUkYkBrq6xmeTMUqaOOjuVJ9xfSciOnqq0VVhWY1JCtnTpUtzc3Pjoo4/46KOPcHd359Zbb7V2bEIIW4qcr3w88rXZtwj0dGKUnys/D9KELL2wmmEejrg6mNTS0SLUad/hQh0f1iV0faF+6pk6sl/6JjAhLCwlq4z6JgPTzmxXArg6aAnychq6K2QZGRk8+eSThIWFERYWxhNPPMHx4+b/1CyEGAC89OA/Ho582avbJI32ZWdmKacbzJ/u0V+lF1b36XYlAPvXUW3vy6elekprGjq/LviCgVFHdroMfn4WmuptHYnoZ7akF2GnUZEQpmvzeOSZwv7BxqSEzMnJia1bz/6j3rZtG05OTlYLSgjRT0TOhxO/QLX5K1zTI3xpaDKwM7PEgoHZnsFgJKOompF9WNDP6TJI30D16IUYUJOaXdb5tfYuEDi5/ydkqWvgp7/AUfNXYsXgtDWtmEnBXjjbt12Bjghw43hRDQ1NBhtFZh0mJWSvvfYad999N3q9Hr1ezz333COzJoUYCiLnA0Y49o3Zt0gI1eGgVbP52ODqR5ZfWUdtQ3PfrpAd/gKaG/CKvwF7jZqUrNKur9dPhbx+XkfWcnDk0Ge2jUP0KyXV9Rw8Wdlmu7JFuL8bTWd+IBpMTErIJkyYwN69e9m3bx/79u3j119/5ccff7R2bEIIWwsYDx7BvTpt6WinIT5Ux8/HCi0YmO21nLDs0xWy/WtBNxKH4MlEB3koHfu7op8Kxub+W0dWdQpyd4GdCxz7HhpqbR2R6Ce2ZSgr6heOap+QRQYobbcG27Zlj2Z9uLu7t/Yfe+6556wSkBCiH1GplFWyjJ96tcoyPdyXjKKaQdU7KKOvW15U5ivjkMZfAyoVsXod+/MqqGvsojavv/cja0n0Zz0OjTWQ8YNt4xH9xta0ItwdtUQHebZ7LtTHBTuNatAV9ps9fG2wNnoUQpwncj401/fqm+X0Qdj+R+wAFwAAIABJREFUIr2oGg8nO3xcu2g9YUkHPwWMMF5pBhun96Kx2cjenPLOX9NSR9Zf51oe+Qp0YRB3OzjpZNtSAEp+sTWtmMSRPmjU7acC2WvVhPm4clQSMoWMThJiiAieonyzPGz+actRfq4M83Dk56ODKCE7c8Kyz74W7l8LwyaAz2gAJocog8ZTuirsB2WM0slfob6fffOqq4DMzUrCr9HCmAVw9FtorLN1ZMLGjhfXcLKirrU7f0ciAtyGVkLm5ubWuk157n9ubm6cPHmyr2IUQtiSRgsRl8Kx76C50axbqFQqpof7si2jmKbmwXEyKqMPh4pTkqE0eR1/TetDns72hPu7ml5HdqKfzbVM2wCGRohcoPx+7CJoqILjMgVmqNuWrhwA6qigv0VEgBt55aepqjPva1J/1GVCVlVVRWVlZbv/qqqqaGpq6qsYhRC2Fjkf6it6VYuUFO5LVV0Te7raYhsgymoaKKlp6Lv6sQMfAyoYd2Wbh2P1OlKzy2juatDyiHhQ20FWP9u2PPIVuPhCUJzye30SOHrAoc9tG5ewuS1pxYzQORHi7dLpNZFnRigNpsJ+s7cshRBDSNgM0Dr16rTlhSN9UKsYFF3704v6sKDfaIR9H0HIheAR2OapOL0XVXVNXX9T6o/9yJrqlRWyiEtBrVEe09pDxHw4+hU0ddHwVgxqTc0GfskoaTMuqSMtI5QGU2G/JGRCiO7ZO8OoWUpCZuaBHg9nOyYGew2Kwv4+bXlxah+UpLUW858rNkTpYG5SP7L+VEeWuVnZnoy8rO3jYxedrS0TQ9Le3HKq6pu63K4ECPJywtVByzFJyIQQQ07kAqg6qXxjN1PSaF/25VV0PfJnAMgorMZBqybQqw8mluxfq2w5jl3U7qkgLycC3B3ZldVdYX9LHVk/6Ud25Euwd4XQpLaPj5wB9m5waL1t4hI2tyWtGJUKEkd6d3mdSqUi3N9VVsiEEENQ+BxQaXo12zIp3AejEbakDexVsvSiasJ8XTs8km9RBgMc+ERZnXTWtXtapVIRq/fqfoVsREL/qSMzGJSB9aMuBjvHts9pHZRtzCNfmn2ARAxsW9OKiQ70wNO5+3YyEQFuHC2oGjRtuCQhE0KYxlkHIYm9qiOLDvLE09luwI9R6rOh4id2QGVem9OV54vT6zhZUdd10117ZwiK7R91ZHkpUFN49nTl+cYuUmZ29odYRZ+qqmvk15zyLttdnCvC343y2kaKqgbHYHpJyIQQpotcAEVHoDjdrJdr1CqmjvJhc1rRgP2p9nRDM3nlp/um5cX+tWDnrKwadSJWf6YfmUl1ZHugrtKSEfbckS+V6QGjZ3f8/KhZyiglaRI75PxyvJRmg7Hbgv4WEWdGKA2WbUtJyIQQpoucp3w8av4qWVK4L0VV9RzOH5hfRDOKqjEa++CEZVODUksVOV85KdmJyAB3XB20PZhracN+ZEaj0mA4NAmc2o/EAcDOSdkeP/wFGLoYCyUGna1pRTjZaZgU0snfjfNEnGl9MVgaxEpCJoQwnWcwBET3atuydYzSAK0jy+irlhfHf1K27qLan648l0atYlKIFyndFfYHnelHZssTjEVHoTRDSTK7MnYR1BZD9va+iUv0C1vSi4kP1eGg1Zh0vc7FHl83B44Okl5kkpAJIXpmzGWQkwxVBWa93N/dkcgAtwHb/iK9sBq1CvQ+ztZ9o/1rwckLRs7s9tK4EC+OFlRRUfv/27vv8CjL7OHj30lvk0bKpJJQkpACAQJRpAgICiJIEbGsKL6y61rWtuqu7i5Y1rbWtaL+XHZdBUQFpK10CIgQIBBKSKMkIT0Q0stk3j8egoApM5PJlHA+1+UFJjPPc4Yh5OS+z31OB4Xw1lBH1nogJHpyx4/rP0HpeyfblleNM+fqyC2t6bTdxZVietAIJUnIhBCGibkZ0MHxtUZfYnSUP3tPVlDTYHsTP7JLqgn3ddP7p3ijNNYoq5CxtyoNUzuRFOGLTgf7T+sx17LQgnVkGWuUJrWewR0/zsldScqO/aCcyhQ9XkqWctBH34L+VlGBajKLqzqeVmEjJCETQhgmIBZ8Irq8bdmk1bE7t9x0cZlJTqkZTlgeXwdNtW02g21LYpg3DnYqPevIWizTj6yyQJnH2dl2ZavYaVBdBPl7ujcuYRVSssvwVzsTfaEDv76iNWoamls4XVHbTZGZjyRkQgjDqFTKacsT24xeaUmK8MHV0d7mti2btS2cKKuhb3cnZOnLQR0M4SP0erirkz3xIV561JENA3sny/Qja11RvbI7f3v6TwR7Z9m2vAq0tOjYmV3GyH5+qFSG9faLuVjYb+HTwyYgCZkQwnAxN4O2EbI3GvV0Zwd7runja3NzLU9X1NKk1XVvy4vaCuXPNWEm2On/T/SwCB/S8s7x7b58mrXtbPM5uUGIherIMlZDr/7gH6Xf4108lRYYR1fKtmUPd6zoPOU1jYzsZ9h2JUD/ADUqVc9ofSEJmRDCcGHJ4ObX5W3Lk+W1nC63na2G1hmW3bpleWwVtDR12Ay2LXdf05u+AR48+c1Bxr25jSV7TtPY3EYiEzHyQh1ZpYkC1kNro1d9tytbxU5TGuOe2d89cQmrYGz9GCirw7193XpEYb9FErJ3332X+Ph44uLieOeddwCoqKhgwoQJ9O/fnwkTJnD2bCdL70IIy7GzV5qVZv2o9MsywugL7S+22VD7i+wLLS+6dcsyfbmykqQZaNDTevdyZ+2jI/n0niS83Rx59rt0rn9jC//+6ST1TZf084ocZf46sqwN0NLcfnf+9kTdpLTqkNmWPVpKdhlRgR4Eerp0/uA2tI5QsnVmT8gOHz7Mp59+yp49ezh48CCrV68mOzubV199lfHjx5OVlcX48eN59dVXzR2aEMIQMVOg4TycNK6vVaSfO6E+rmw7bkMJWUk1gZ7OeLo4ds8NKguUlaSE25RaPQOpVComxAay8qHrWDxvOMHervx15RFGv76Fz3bkUtvYbJk6sozV4KFRTlgawtVbGTh+dKXSVFb0OPVNWvacqNC7O39bojWenCyrufwHDxtk9oTs2LFjJCcn4+bmhoODA2PGjOG7775j5cqVzJ07F4C5c+eyYoX8RCSEVeszRhlxY+S2pUqlYkyUPz/llLW9tWaFcrp7huWR7wCd3qcr29P6Z/vN767lqweS6evvwUtrjjHqtS18uLMAbbAZ68ia6iBrozLlwYCauItip8G508o2q+hxUk+epaG5xeD+Y5eKDlTTovulpMBWmT0hi4+PZ8eOHZSXl1NbW8vatWvJy8ujuLiYoKAgADQaDcXFbTedXLRoEUlJSSQlJVFaajs/WQvR4zi6KkXXGWuNLroeHeVPTaO28/5ZVkCn05FTWkPf7izoT18OwYOhV1+TXE6lUjGirx9fz7+G5b+7lvgQL15ff5xP84JpOXOQynNmaDuSuw2aagyvH2sVPVmZfSmnLXukHdmlONqrGB7pa/Q1esoIJbMnZAMGDOCZZ55h4sSJ3HTTTSQmJmJvf3mDRZVK1e7R1/nz55Oamkpqair+/sYvcQohTCBmitIrysii6xF9e+Fgp7KJ05bF5xuobmjuvhWysixlFcjAYn59JUX4snjecFY+dB1Vmmuwo4U/vb2IN/6XQUWNcXWAeslYDc6eEDHauOe7+SqzL2XbskdKySpjcLgP7s4ORl8jopcbTg52Nl9HZpGi/vvvv599+/axfft2fHx8iIqKIjAwkMLCQgAKCwsJCAiwRGhCCENETVRWL1pH4hhI7eLIkN4+NtGP7OIJy+5aIUtfDqggbkb3XP+CQWHe/PH+u2mxc2KGTw4fbs1h5Gub+fvaY5RU1Zv2Zi1apclt/wl6TRxoV+w0qMiF4sOmi01YXHl1A0fOnGeUEe0uLuVgb0c/fw+bb31hkYSspKQEgNOnT/Pdd99x5513MnXqVBYvXgzA4sWLmTZtmiVCE0IYwtVHaaNwzLiEDJT2F0fOnKe0qsGEgZledonyj323rJDpdMrsyoiR4Blk+utfydEVu7Dh3OCaxY+PjWZibCCf7chl1GtbWLDqCIWVdaa5T94eZUi4sduVrWKmgMpOti17mJ05ypa5Me0urhSjUZMpCZnhZs6cSWxsLLfccgsffPAB3t7ePPvss2zYsIH+/fuzceNGnn32WUuEJoQwVMwUKM+C0kyjnj66v1J6sMPK219kl1ajdnHAX+1s+osXpkFFTrdtV7YpYiQUHaK/p5Z35gxm05PXMy0xmC93n2LM61v58/fp5HV1HE3GauVEZ78JXbuOu58SryRkPUpKVimeLg4MDPXu8rWiNWqKztdTWdtkgsgswyIJ2Y4dOzh69CgHDx5k/PjxAPTq1YtNmzaRlZXFxo0b8fU1vsBPCGFG0ZOUX43ctowL9qSXu5PVb1tmXzhhaehoF72kL1f6bcVONf2123PFXMtIP3denzWILU9dz21JoSxPzWfsP7byx28OcqKsxvDr63TK34nIMUrX/a4aMBXKMqEko+vXEhan0+lIySpjRF8/7O26/jXVWtifYcMjlKRTvxCia7xClZOBRra/sLNTMaq/Hzuyymhpsd6i7eySmu6pH2vRwuFvldmNrj6mv357QocpsyKv6EcW5uvGy9MT2Pb09dx9TW9WHTzD+De38tiSA4ZtZZYchbMnu75d2WrALYDKelbJaitg7dNQccLSkdikE2U1nKmsN8l2JVxy0tKGC/slIRNCdF3MzVCQCucLjXr66Ch/ymsaOXLGOn+6raxtoqy6oXvqx07tgqpCZXalOTm6KElZOw1ig7xcWTA1jpRnxvHAqD6sO1zEDW9u47Mdue3PyrxUxhpApbStMAW1BsKvtZ6EbOMC2PMJLLkLGo1YQbzKpWQr45K60n/sUhpPFzxdHGy69YUkZEKIrou5Rfn1uHGrZKMu1JFtt9I6sosjk7pjhSz9G6XBbtQk01+7MxEjofAQ1J1r9yH+amf+NHkAGx4fw7BIX15ac4yp7+8kLa/95wDKdmXoMFAHmi7e2GlQckRpEWJJ+ftg/7+hz/VQegxWPiwtOQy0I6uMMF9XevdyN8n1VCoVMRpPSciEEFc5/2jw7Wv0tqW/2pm4YE+r7UeW011DxZsblBWfAVPAyc2019ZH5ChAB6d/6vSh4b3c+OLeYXx41xDKaxqY/uFOnl+RTmVdG0XU5/Kg8KDptitbDbiQ+FtylaxFC2ufBI9AmP0fGP9XZcLCrn9aLiYb06xtYXdOeZfGJbUlSuPB8eIqdDaaHEtCJoToOpVK+eZ7YnuHqy0dGR3lz/5TZ6mqt75TUtml1Tg52BHma+KkKXsT1J+D+K6NSjJaSNKFOjL9xiipVComJwSx8Ykx3Dsigq9+Ps34N7exMq3g8m+CrYl5awJlKl4hEDrcsgnZ/sVw5gBMfEk5rHDdY8rK3ca/Qe5Wy8VlQw7mn6Oqodlk25WtojWeVNU3U1hp4n56ZiIJmRDCNGKmQEszZG806uljovxpbtGxK8cM43wMlF1STR8/d5OcBrvM4eXg6qsM0LYERxcIG27woHG1iyN/uyWOVQ+PJNjbhT8sSeM3n+/55TRmxmrwjzHZCKjLxE6DokNKo1hzqymHTS9A75G/zBtVqWDaB+AXBd/cp8zdFB3akVWGSqVM6jClGBsfoSQJmRDCNEKHgXuA0e0vhoT74O5k33n7i/rzsOdT+PkTo+5jjOySavqaeruyoVqZAxo3HewdTXttQ+hRR9ae+BAvvv/9dbwwLY6Deee48Z3tfLxuD7pTu0y/XdmqtTXI0VXdc/2ObFqo/P2b/IaSiLVyVsOcr5TtzCV3KQPVRbtSsspICPHC260L0xvaEBXQ2vpCEjIhxNXMzg5iJkPWBqU2ykBODnZc29ePbZmlbdeAlByD1U/AWwNg7VOw7mk48F8TBN6x+iYteWdrTd/y4vhaaK4zbzPYtkSMBHTKaU8j2NupuOfaCDY9OYYb4zRk7vgWlU7LQfeRpo2zlXc4BA/pdNuyrlHL/44U8daGTGobm7t+39ZC/msehMDYX3++V1+YsUhZvVv9uBT5t6OqvokDeecY2cVxSW3xcnMkyMuFTBttfSEJmRDCdGKmQGM15G4z6uljov3JP1v3y9aXtgkOfwdf3AwfXgMHvlQahN6/URk4veYJKEo34Qv4tdzSGnS6bijoT18OnqEQlmza6xrKwDqy9gR4uvDPOwbz5z65lKh6ceuKGh5bcqB7RmLFTlMG2l+xPVhR08g3qXk88O9UBr/4I7/9zz7e25TFN6n5XbvfxUL+ABjzTPuPi74Jrv8zHPwa9izq2j17qN25FWhbdCbrP3alaI1aVsiEEILI0eDkYfS25ZgL7S/2HjoCW16Bt+Nh+X1QmQcTXoAnjsH0jyBsGMz8HFy8YelvjD5IoI/WlhcmTchqyiFnk9J7zM7C/wwbWUfWpsZa/Ip24DtkOo+Mi2JNeiHj39zKl7tPmbbp7yXblnkVtXyecoLbP/mJpJc28MflhzhSUMmcYeF89f+SiQv25Os9p7t28m7/vy8U8r/c+dSB0X9Ueq/9789wcqfx9+yhUrJKcXW0Z2jv7mmCHB2oJqekmiZ9euVZGUnIhBCm4+AM/Sco23EtWsOeq9MRfn4f/3J/n1k7boJtr4EmAe5cBo8egOv+AO6XFAF7BMDsxUqytvKhbtsiyimpRqVSRguZzNEVygEIS29XtooYpaw01p3t2nVyt0BzHQ6xU3hiYjTr/jCauGAvnl9xmBkf7eKoCRr/6nQ6jtb7UeIexdFN/2HU61t4cfVRKuuaeHhsP1Y/MpKdz45jwdQ4RvTzY87wcDKKqkgvqDTuhrUVSu3YpYX8HbGzg+kfg08EfDMXKguMu28PtSO7jOGRvjg72HfL9aM1ahq1LZwqt71mvZKQCSFMK2YK1JRCfqp+j2+oUor0P7wWFk9hOIf5V8vNNPw+Fe5eDlE3gl07/3iHX6OsnGWshl3vme41XCK7tJowHzdcHE34DSR9OfhFQ2C86a7ZFRfryDrvR9ahjDXg7HXhesqq4lcPJPP27YPIq6jllvdTeGn1UWoaDKvpata2sDu3nBd+OMqo17cw+b0d/LsykVhtBi+P78XWp65n/WOjeWJiNPEhXpfNG506KBgXRzuW7s0z7jW1V8jfERcvpci/qQ6W/caomsqe6My5OnJLa0ze7uJSv8y0tL1tS0nIhBCm1X+CMii7s23LkmOw5kl4M0Yp0nd0gWkf8vOtKbzYeAep5731u981v7/QB2pht2wR5VwYKm4ylflwepeyOtYdg8qNETIUHFy6VkembYbj65QE+pJToyqViumDQ9n05BhmJ4XxWcoJbnhrG/87UtThNmJ9k5YNR4t56puDDHt5I3MW7ebLn08RFajmtZkJzHvgMQDu8jxIRAerl16ujkxOCGJV2hnDi/sL9sG+xZD8u7YL+TviHw23fqRcY+1Thj23h2odl9Rd9WOgTNOwt1PZZOsLB0sHIIToYVy8lFqyjNXK6tWlSYe2Sfn43s+VmiV7Z4ifCcP+H4QOBWB4QzOO9kfYllnKdfqcxFKpYOr7UHxEqTf77XZl7qEJaFt05JbVMDrKhB3FD3+r/Gru2ZUduTjXcrvx18jbDXUV7ba78HZz4pUZCcwaGspz36fz2//s44YBASyYGkeoj9Jw92xNI5szSvjxaBHbM8uoa9KidnFgfEwAE+M0jI7yx8P5km9bAbHKacvk33YY2pxh4Xy3v4C16UXMGhqq3+tp0So/MHgEwPXP6vecK8VOhVFPwo43lZOhSfcZd50eIiWrDH+1M9GB6m67h4ujPRG93GxyhUwSMiGE6cXcrJyALM2AgAHK0PH9i2Hfv5RB2t7hcMNCGPyby+vCAHdnB4ZF+LI9s5Q/Tx6g3/1cPGH2v+HT8bB8HtyzCuy7/s9bXkUtjc0tpm15kf6NsiLl28d01zSFiFGw9RWlZsrN1/DnZ6xREux+N3T4sKG9ffjhkZH8a+dJ3tqQyYS3tjNneBgZhVXsOamcwNN4unBbUigTYzUk9/HF0b6dzZzYabD1Vagq7nBm5rAIH/r4ubN072n9E7LWQv4Zn3ZeyN+Rsc8pY6TW/hEC45QDFFehlhYdO7PLGB3lf9mWcneI0Xhy+IyRNYMWJFuWQgjTi56s/JryDiybC+/EK984A+MvFOmnwcjHfpWMtRod5U9GURXF5w0YgRIYB7e8A6d2wuYXTPAilIawgOmawpYeV4rnraWY/1IGzLX8FZ0Ojq1WJg44d/5n5WhvxwOj+7DxyTGM7O/HFztPUlbdwO/G9GHVw9fx05/G8cK0eEb292s/GQMlIUMHGT90eD+VSsXsYWHsPXn24nvaoYuF/Nd1/b2ys4eZnyljn5b+BqqKunY9G3Ws6DzlNY3d0n/sStEaNacrak3Tf86MJCETQpieZ5DS3+rQEmW+X/Lv4NH9nRfpXzD6QvsLg4eND5oDSfNg57tKgtBFJm150VClrJKo7JXu/NamK3VkRelQedrg7vwh3q58ek8S6QsmsuGJMfzxxhgGhnrrv4LiH6OMLNJjtuWMISE42KlYlqpHcf/FQv5/mKbOz9UHbv8vNJxXfkBpbuz6NW1MSlb314+1igpUo9NBZrEeybcVkYRMCNE9bnkXZnwGT2bAjS8btEU3IEiNv9q58zFKbbnpVQgeDCsehPIcw59/ieySavzVzni5dnG0UVURfDFZSXam/tNkNW4m5eBsfD+yjDWACqImGXVrtYuRf74qlbJKdjIFaso6fGiA2oXxAwL4bn8+jc0d9KjqSiF/RzTxynuft1vpUXaVSckuIyrQg0BPl26/V+tMy0wbqyOThEwI0T008TDwNnB0NfipKpWK0f39SckuQ2toQ1EHZ7htMajslNWILswVzCmtpq9/F/uPlWbCZxOU5PDOpTD4rq5drztFjIKiw8qWnSEy1igtSDxMePhBX7HTQNeiVzPiOcPCKatuZHNGcdsPaGmBNU91rZC/IwmzYMQjsPdTs4z9shb1TVr2nKjQ75COCYT7uuHiaGdzhf2SkAkhrNLoKD/O1TZxKN+ILvw+vZVi7OJ05RusEXQ6HdldbXlx+mf4v4nKzMp7VystQayZMXMtz55U/pxjpnRXVB0LjFdWX/XYthwd5Y/G04Ul7fUkO/BvZSTTxJe6VsjfkfELIHKMMu+yYH/33MPKpJ48S0NzS7f2H7uUnZ2KqEA1x4u73ojYnCQhE0JYpVH9/VGpYHtmx1tR7YqaqIyxSftSOTFnoNKqBqrqm40/YXnsB/j3VHD1hfs3QMgQ465jTiFDwcHVsDqyjDXKrzGTuyemzrRuW+Zu63Rlz95OxW1JoWzLLOXMuStWTmsrYOMC0xTydxiEA8z6AjwClSL/aiO25W3MjuxSHO1VJEe2fYinO0QHqjleJDVkQgjRZb7uTgwM8WJ7Vhe+YV3/J+hzvbJKVnjQoKe2nsbrF2BEz6Q9nyrfbAPjlWTMN9Lwa1jCxToyAxOygDjLtvEYMBV0WmVkVydmJ4Wh0/HrgeObXjC8I7+x3HvB7f+B2jKld57Wtk4DGiolq4zB4T64O5uv01a0Rk1ZdQPl1bYzJUESMiGE1Rod5c+B02eprG0y7gJ29soQcne/C0PI9Z/VaNQJS51OWWVZ+xRET4K5P7Tb2sNqRYyCYj3ryGrKlDYZBp6uNLngweAVDkdXdfrQMF83RvbzY1lq3i8Dzwv2Kz3ykn+rtE8xh+BE5eDLyR2w4a/muacFlFc3cOTMeUaZqX6sVYxG2XK2pY79kpAJIazWmCh/WnSwM8fIbUtQkrHb/gXnC+D7B5XCbT1kl1Tj4exAoKezfvdpboTvfwcpb8PQ+2D2f8DJzfi4LcWQOrLM9UpBvaUTMpVK6YqfsxnqO28IevuwMArO1Sl/r1paut6R31iD5sDw38LuD+DQN+a9t5nszCkHzNPu4lJRGuUHKVsq7JeETAhhtRLDvFG7OLDteBfrbMKGw8SXIXMd7HxHr6dkl1TTN8BDv55Y9efhq9uUvmvjnocpb5tkUoBFhAy5UEemR/uLjDXgFQZBg7o/rs7E3gotTXB8facPnRgXiLebo1Lc31rIP+FFZeyXud34MoSPgFWPQOEh89+/m+3MKsPTxYGBoXrOpjURfw9nfN2dyCyWhEwIIbrMwd6O6/r6sT2rtMNB1HpJ/q3SkHXzi3Ci85mN2SXV+hX0ny/8pcfYtA+VgwTWMjTcGPrWkTXWKCtSMTdbx+sNGQqeIXqdtnR2sGfG4FD2HMmiZeNCJSEaONsMQbbB3hFmL1aaxy692/CWI1ZMp9ORkl3GiL5+2NuZ9++ISqUiOlAtK2RCCGEqY6L9Kays12/kTUdUKqUxZ69+yrzL84XtPvR8fRMlVQ30DeikB1npcfh8AlTkWn+PMUNE6lFHlr0Jmustv13Zys5OKe7P3qhMRejE7cPCeEy1VNnivNlEHfmN5RGgFPlXFcK39yuDzXuAE2U1FJyrM/t2ZatojZrM4qpfagWtnCRkQgirNjrKyDFKbXFWK7VdjbUXTre1fVggp/WEZUcrZKd3w+cTobkB7lvT6VBtmxIxSvn11M72H5OxBly8ldUlaxE7DbQNkPm/Th8arc3iDofNfO94M7oAE3bkN1ZokjKqKWezsorbA6RkK7Wf5uo/dqVojZraRi0FV7Y4sVKSkAkhrFqItyt9/d1Nk5ABBMTA1PeU04EbF7T5kF9aXrSTkB1dBYunKgcG/t8G5ZRfTxI8pON+ZNompaA/epJ11cqFJYOHpvNty5YWWPsUDU6+LDg/lQN5RjQf7g5D58LQeyHlbb7/8gOW7c2zqbYNV9qRVUaYryu9e3Vx2oWRoi+MULKVbUtJyIQQVm9MVAB7TlRQ32SirZyEWTDsAfjp/Ta/eWeXVuNkb0e4bxunJH9eBMvuUQrZ5/0IPhGmickZ1ox4AAAc4ElEQVSaODhBeHL7CdmpXVB/znq2K1vZ2cGAWyBrg1Lj1p4D/4GCfahufAmtk5qle/QYOG4uk17njDqBiVkL+eS7dQx7eSOzP/6Jz3bkcqq8g9dkZZq1LezOKWekmdtdXCoqUEnIjhfZRsd+iyRkb7/9NnFxccTHx3PHHXdQX1/PvffeS2RkJImJiSQmJpKWlmaJ0IQQVmh0lB8NzS3szi033UVvfFkpBF/xEJRlX/apnJJqIvzccLC/5J/IlhalX9S6P0L0ZLhnpe31GDNExEiljqymjT/zjDXKClrf8eaPqzOx05RRVVkb2v58a0f+8BG4DLmDWwYG88OhM1Q3WEdz1lOVzcw++yAtDi78EPolj46NpKqhmZfWHGPMG1u58e3tvPnjcdLzK7t+0KUbHcw/R1VDMyP7WWC+6QUezg6E+rhyvNg2OvabPSErKCjgvffeIzU1lcOHD6PValmyZAkAb7zxBmlpaaSlpZGYmGju0IQQVio5shdODnbGj1FqS+sQcntHZcWrsfbip341w7K5Eb7/Lex8F5LuVwqwbbHHmCHaqyPT6ZSErO846/wz6D0C3Pza37bc/KJSyH+hI//tw8OobdSy+uAZ88bZBp1Ox4JVRzhn74d20j9wKz3IY67rWPeHUex4eix/mRKLj7sjH2zJ5pb3Uxjx6mb+tvIwKVllNGn1669nLjuyylCpYERfy/7QEqNRywpZR5qbm6mrq6O5uZna2lqCg4MtEYYQwka4OtmTHOnbtTFKbfEOg5mfQslRWPME6HTUN2k5XVH7S0F/fSX8dxakL4Nxf4Gb31QmAPR0wUPA0e3X25aFaXA+3/q2K1vZ2cOAKUphf9MVxdxnDkDqFzB8PmjiARgc5k3/AI/2B46b0Y9Hi9lyvJTHbuiPd9JspU3Llleg+Ahhvm7cPzKSJfOvJfX5CfzjtkEkhHixNDWPuz//maEvbuCxJQdYm15IjRWs9qVklZEQ4oWPu5NF44jWqMktraGx2boS1raYPSELCQnhqaeeIjw8nKCgILy8vJg4cSIAzz33HAMHDuTxxx+nocF2CxmFEKY3Jsqf7JJq05+Y6neD0qH94New71+cKq+lRQd9Azx+6TF2aifc+jGMfso6em6Zg4OTUiR/ZUKWsQZUdhB1k2Xi0kfsNGiqUVpztGppUWaauvvD2D9d/LBKpeL2YWGk5Z2z6JidukYtL/xwlBiNmntHRCgfnPwmuHrDigcvOxHs6+7ErKGhLLoniQN/mcin9yRxY5yGbZml/P6/+xn84gbm/WsvS/acprTK/N9Lq+qbOJB3zqL1Y62iAtU0t+jILbP+bUuzJ2Rnz55l5cqVnDhxgjNnzlBTU8OXX37JK6+8QkZGBnv37qWiooLXXnutzecvWrSIpKQkkpKSKC018U/LQgir1dr+YrupTltedvGnlXqodU9TevwnAGIdzig9xs6ehDuXQeIdpr+vtYsYCSVHLq8jy1ijtLqw5vq5iFFKo9Vjl8y2TPsSClJh4q878s8YEoqjvYqlFlwle39LFgXn6nhhWvwvtYvuveDmt6DwoDKSqw2uTvZMiA3kjdsGsfe5G1g6/xp+c01vskqqePa7dIb/fSMzP9rFJ9tyOFFmnkMBu3Mr0LboLNZ/7FK2NNPS7AnZxo0biYyMxN/fH0dHR2bMmMGuXbsICgpCpVLh7OzMfffdx549e9p8/vz580lNTSU1NRV/f8sVCwohzKt/gAdBXi7dk5DZ2dE47RPqnXsRtf0hJtjvo9/qmaBthPvWQj8rLF43h4t1ZBdWycpzlO3dAVMsF5M+7B2VLdXj65Q+cbUVsOFvEH4tDLz9Vw/3dXdiYpyG7w7k09Bs/qasOaXVLNqey4whIQyP9L38k7FTIX4WbHut09FKDvZ2JPfpxV+mxLL9j2NZ/9goHr8hioZmLa+sy2DsP7Yy4a1tvL4+g63HS6ioaeyW15OSVYqroz1De/t0y/UNEennjqO9yiZaX5i9gUx4eDi7d++mtrYWV1dXNm3aRFJSEoWFhQQFBaHT6VixYgXx8fHmDk0IYcVUKhWj+/uz9nAhzdqWy09AGqmhWcuOzDLWphey4VgxfRoeZLnzQj51fBPc+8Pd34JPbxNEb6OCB/9SRxY7TVkdA+WUqbWLvRUOfAm5W5V6svpKpfFqO1vOc4aFseZQIT8eKeaWQeara24t5HdxtOdPkwa0/aDJbyjjvlb8Hh7YrGwnd0KlUhGj8SRG48mj4/tTcK6ODUeK+PFoMZ9sz+XDrTkAhPq4MjDUi4QQbwaFehEX4oWXq2OXXtOO7DKGR/ri7GD5WksnBzv6+HnYxAqZ2ROy5ORkZs2axZAhQ3BwcGDw4MHMnz+fSZMmUVqqzKtLTEzk448/NndoQggrNzrKn6WpeaTlnSMpwrfzJ7ShvknL9sxS1qYXsulYCVUNzXi6OHBjnIabEwZDXSBkr1e2ityMu0ePcWUdWcYa0CTYRpIaOQacvWDb61CwD5J/d7GQvy3X9fUjxNuVpXvzzJqQrU0vYkdWGQunxuGvdm77QW6+cMs7sORO2PEPGPtng+8T4u3KvddFcu91kVTVN3G44DyH8s9xqKCS9PxK1qYXXXxspJ87CSFeDAz1YmCoN3HBnrg765cunDlXR25pDXcODzc4xu4SrVGz79RZS4fRKYu0WF64cCELFy687GObN2+2RChCCBsysp8fdiqljsyQhKy+ScvW461JWDE1jVq83RyZlKBhckIQI/r64eTQuuI2BwbP6Z4XYIsiR8GmF6DkGOT9rByAsAUOThAzWTms4R5wWSF/W+zsVMxOCuPtjZnkVdQS1lZTYBOraWjmxdVHiQv25O5rOklyY26GgXNg+z+UFcpg41tDqV0cubZvL669pCXF2ZpG0gsqSS+o5FD+OVJPVrDqQisQlUoZIzYw1FtZTQv1IjbIExfHX6+AtY5Lsob6sVbRGjWrDp6hqr4JtUvXVv+6kxXNvBBCiI55uTmSGObNtsxSnpgY3eFj6xq1bDlewtr0QjZnlFDbqMXHzZFbBgUzOSGIa/v2wtEE2549Xmsd2Y/PAzrrbXfRlviZSkLWRiF/W25LCuWdTZl8k5rX6d8vU3hvUxZF5+v58O4h2NvpcXp30qvKFuyKB2H+VqWXnon4uDsxOsr/4uEZgJKqeg4XVHIoX1lF25ZZyrf78wFwsFMRFai+uIo2MNSLqEA1KVll+Kudib7QJd8atMaSWVzF0N7Wu+otCZkQwqaMjvLn3U1ZVNQ04ntFj6PaxmY2Z5SwLr2IzRkl1DVp8XV3YlpiCDcnBHFNH1+T1J5dVVrryLI3gndvCLSh+t5+N8DDqeDXX6+HB3u7MibKn2Wp+fzhhij9kiQjZRZX8XnKCW5PCmNIuJ7F764+yhzWr2YrRf7j/9pt8QEEqF0YF+PCuJhAQKl3Kzpfz6F8ZRXtUH4l648UXezh5mRvhw4dUwYGo7Ki9jCtMy2PF1VLQiaEEKYyJsqfdzZmkZJdxtRBwdQ0NLMpo4S1hwrZmllCfVMLfh5OzBwawuT4IIZHShLWJfaOEH4N5GyGmCm21YdNpdI7GWs1Z1gYv/tyP9szSxkbE9AtYel0Ov668jAeLg48MynGsCdH3QiJd0PKO8pqZcjQbomxLSqViiAvV4K8XLkxTgMoryX/bN3FJO14cRV3JVtP/RgoBxfcneytvmO/JGRCCJsyMNQbbzdH/vPTSVYfPMO2zFIamlvwVzszOymMSReSsO5c3bjqRIy8kJDZwOnKLhoXE4ifhxNL9p7utoRs1cEz7M6t4O/TE361yquXG1+G3C3Kqcv528DRxfRB6kmlUhHm60aYrxs3DwyyWBwdUalURGnUVt/6QhIyIYRNsbdTMSbKn5VpZwj0dOaO4eFMiteQFCFJWLdJmqfMh+x9naUj6XZODnbMHBLK5yknKK1qaP/ko5HO1zfx0ppjDAr14vZhYcZdxNVb2br8ciZsfQUmLOz8OVe5GI2a9YeL0Ol0VrWdeilZxxdC2JyFU+NY9fB1/PTseBZMjSO5Ty9JxrqTqw8MnWtb25VdcFtSGM0tOr67UMBuSu9syKKsuoEXb43v2t/ZfjfAkLmw6z3I22u6AHuo6EA1Z2ubLDJKSl+SkAkhbI63mxMDQ72xkyRMdIN+AR4Mi/Bh6d48dDqdya57rPA8i386yZ3DwxkY6t31C058CTxDlFOXVw5S74kaa6Cx1qinRl8YoWTN25aSkAkhhBBXuH1YOLllNew9aZqGoi0tOv6y4jBero788UYTtdRw8YSp/4TyLNj8kmmuaY20TZD6f/DeYPjpfaMu8ctJS0nIhBBCCJsxOUGD2tmBJXtPm+R63x0oIPXUWZ6dFIO3mxGF/O3pO1ap8fvpAzi923TXtQY6HRxdBR9eA6sfB58IZQKDEXzdnfBXO3O8WBIyIYQQwma4OTkwNTGYtemFVNY1delalbVNvLL2GEPCvZk1JNREEV5iwgvgHaZsXRq5pWd1Tu2CzyfAst+Ayg7mfAXz/gfhyUZfMkajlhUyIYQQwtbcPiyM+qaWiyOEjPWPH49ztraRF2+N7566R2c1TPsAKnKVMVe2rOQYfDUHvpgElflwy3vw4E9Kz7UuHiqJClSTWVyFtsV0dYGmJAmZEEII0YaEEC8GBHmy7EInemOk51fy5c+nuOfaCOKCOx/fZLTI0TB8Pvz80S/D4G1JZQGsfAg+GgGndsL4v8Ej+5XTvfam6dAVrVHT0NzC6QrrXEWUhEwIIYRog0qlYs6wMNILKjlcUGnw81tadPxl5WF6uTvzxMSobojwCjcsUOqsVj4EDdXdfz9TqDsHG/4G/xwCh5ZB8oPwh4Mw6glwMu2A95iLhf3W2bFfEjIhhBCiHbcmhuDkYMeyVMNXyZal5pGWd47nbo7B08WxG6K7gpM73PoRnD0FGxd0//26oqkedv0T3h0EO9+F2GnK3NGb/g5u3TNvsn+AGpXKeltfSEImhBBCtMPLzZHJ8Rq+P1BAfZNW7+edrWnktfUZDI/05dbEkG6M8Aq9R8A1D8LeTyF3m/nuq68WLaR9De8nwY/PK7M4f7sdZiwCn97demtXJ3t6+7qRaaUnLSUhE0IIITpw+7BwquqbWXe4UO/nvP6/DM7XN/PitHjzj+oZ9xfw7QurHoYGK0k+dDrI2gCfjIYVvwO3XnDPSvjNdxA00GxhRFvxTEtJyIQQQogOXNPHl9693FiqZ3H/gdNnWbI3j3nXRVxsSGpWTm7K1uW5PNjwV/Pf/0oF+2DxLfDfWdBYDbP+Dx7YAn2uN3so0RpPTpbVGLTaaS6SkAkhhBAdUKlUzE4KY3duBSfKajp8rPZCIX+A2pk/3GCGQv72hCfDtQ8pHe5zNlsmhvIc+OZe+HSc0s5i0hvw0F6Inwl2lkk/ogPVtOggu8T6Dj1IQiaEEEJ0YtbQUOztVJ0W93/18ykOF5zn+Ztj8XA2TbsGo417Hnr1h5WPQL0ZTxZWl8Kap+CD4ZD5I4x5Bh49AMnzwcGEUwqMYM0jlCQhE0IIIToR6OnC2OgAlu/Lp0nb0uZjyqobeON/x7muXy+mDAwyc4RtcHRVti6rzsCPz3XvvRqqlUMEGxfAe4nKytyQuUoiNvbPytxNKxDRyw0nBzurHKFk4fRdCCGEsA1zhoWx8VgxWzJKmBin+dXnX12XQV2TloVTLVDI356wYTDiUdj5DgyYBv1v6Po1dTplKkD+Xsj7GfL2QskR0LUAKhhwi9LY1a9f1+9lYg72dvTz97DKwn5JyIQQQgg9XB/tT4DamaV7836VkKWerGD5vnwevL4v/QI8LBRhO67/E2Suh1WPwO9/Aldvw57fWANnDkDeHuW//L1QW6Z8ztkTQpMg5mkl+QtJMvz6ZhajUbMrp9zSYfyKJGRCCCGEHhzs7Zg1NJSPt+VQVFmPxssFgGZtC8+vOEywlwuPjLO+VSEcXeDWD+GzCfC/Pyu/b49OB+dOKateeT9D/h4oOgy6C6cSe/WHqJuU5Ct0OPhHg529eV6HiURr1Hx3oIDK2ia83MzQsFdPkpAJIYQQepqdFMaHW3P4dn8+D41Vkq9//3SKjKIqPr57CG5OVvptNWQojHwcdvwDBkyF6JuUjzfVwZm0C8nXXmUFrKZE+ZyTB4QMUcYYhQ5XVsK6qYu+OUVdKOzPKDpPcp9eFo7mF1b6N0cIIYSwPhF+7lzbpxdL9+bx4Ji+lFU38NaGTMZE+XNjG3VlVmXM03B8HfzwB8idriRhRYegpVn5vG8f6DtOWf0KS4aAWJtb/dJH60zLzOIqSciEEEIIWzVneBh/WJLG7txylqXm0djcwoKpcdZTyN8eB2dlu/LzCbB/MQQPgRGPKKtfYcPB3c/SEZqFxtMFTxcHqyvsl4RMCCGEMMCNcRq8XB15YfVRMoqqeHRcPyL93C0dln6CE+HJ4+CsBnvrqZ8yJ5VKRYzG0+p6kUkfMiGEEMIALo72TB8cQkZRFaE+rvx+rBUW8nfEzfeqTcZaRWk8OF5chU6ns3QoF0lCJoQQQhjoruRw3J3sefHWeFwce16dVU8XrfGkqr6Zwsp6S4dykWxZCiGEEAbqH6jm8MIbrb9uTLQp5pIRSsHerhaORmGRFbK3336buLg44uPjueOOO6ivr+fEiRMkJyfTr18/br/9dhobGy0RmhBCCKEXScZsV1RAa+sL66kjM3tCVlBQwHvvvUdqaiqHDx9Gq9WyZMkSnnnmGR5//HGys7Px8fHh888/N3doQgghhLgKeLk5EuTlQqYVzbS0yApZc3MzdXV1NDc3U1tbS1BQEJs3b2bWrFkAzJ07lxUrVlgiNCGEEEJcBaI16qt7hSwkJISnnnqK8PBwgoKC8PLyYujQoXh7e+PgoJS0hYaGUlBQYO7QhBBCCHGViA5Uk1NSTZO2xdKhABZIyM6ePcvKlSs5ceIEZ86coaamhvXr1+v9/EWLFpGUlERSUhKlpaXdGKkQQggheqpojZpGbQunymssHQpggYRs48aNREZG4u/vj6OjIzNmzGDnzp2cO3eO5mZlfEN+fj4hISFtPn/+/PmkpqaSmpqKv7+/OUMXQgghRA8RrbGuwn6zJ2Th4eHs3r2b2tpadDodmzZtIjY2lrFjx7J8+XIAFi9ezLRp08wdmhBCCCGuEn39PbC3U1lNx36zJ2TJycnMmjWLIUOGkJCQQEtLC/Pnz+e1117jrbfeol+/fpSXl3P//febOzQhhBBCXCVcHO2J6OVmNQmZRRrDLly4kIULF172sT59+rBnzx5LhCOEEEKIq1CMxpPDZyotHQYgo5OEEEIIcZWK1qg5XVFLbWOzpUORhEwIIYQQV6eoQDU6HWQVV1s6FEnIhBBCCHF1unSmpaVJQiaEEEKIq1K4rxsujnZW0fpCEjIhhBBCXJXs7FREBao5Xnze0qFIQiaEEEKIq1d0oJrjRVJDJoQQQghhMdEaNWXVDZRXN1g0DknIhBBCCHHViraSwn5JyIQQQghx1bqYkBVLQiaEEEIIYRH+Hs74ujtZfIXMIqOThBBCCCGsgUqlYvF9wwn2drFoHJKQCSGEEOKqlhDqZekQZMtSCCGEEMLSJCETQgghhLAwSciEEEIIISxMEjIhhBBCCAuThEwIIYQQwsIkIRNCCCGEsDBJyIQQQgghLEwSMiGEEEIIC5OETAghhBDCwiQhE0IIIYSwMJVOp9NZOghj+fn5ERER0e33KS0txd/fv9vvI7qfvJc9h7yXPYe8lz2LvJ/tO3nyJGVlZW1+zqYTMnNJSkoiNTXV0mEIE5D3sueQ97LnkPeyZ5H30ziyZSmEEEIIYWGSkAkhhBBCWJj9ggULFlg6CFswdOhQS4cgTETey55D3sueQ97LnkXeT8NJDZkQQgghhIXJlqUQQgghhIVJQtaB9evXEx0dTb9+/Xj11VctHY7ogoiICBISEkhMTCQpKcnS4QgDzZs3j4CAAOLj4y9+rKKiggkTJtC/f38mTJjA2bNnLRih0Fdb7+WCBQsICQkhMTGRxMRE1q5da8EIhb7y8vIYO3YssbGxxMXF8e677wLytWksScjaodVqeeihh1i3bh1Hjx7l66+/5ujRo5YOS3TBli1bSEtLk+PYNujee+9l/fr1l33s1VdfZfz48WRlZTF+/Hj5oclGtPVeAjz++OOkpaWRlpbG5MmTLRCZMJSDgwNvvvkmR48eZffu3XzwwQccPXpUvjaNJAlZO/bs2UO/fv3o06cPTk5OzJkzh5UrV1o6LCGuSqNHj8bX1/eyj61cuZK5c+cCMHfuXFasWGGJ0ISB2novhW0KCgpiyJAhAKjVagYMGEBBQYF8bRpJErJ2FBQUEBYWdvH/Q0NDKSgosGBEoitUKhUTJ05k6NChLFq0yNLhCBMoLi4mKCgIAI1GQ3FxsYUjEl3x/vvvM3DgQObNmydbXDbo5MmTHDhwgOTkZPnaNJIkZOKqkJKSwv79+1m3bh0ffPAB27dvt3RIwoRUKhUqlcrSYQgjPfjgg+Tk5JCWlkZQUBBPPvmkpUMSBqiurmbmzJm88847eHp6XvY5+drUnyRk7QgJCSEvL+/i/+fn5xMSEmLBiERXtL53AQEBTJ8+nT179lg4ItFVgYGBFBYWAlBYWEhAQICFIxLGCgwMxN7eHjs7Ox544AH5+rQhTU1NzJw5k7vuuosZM2YA8rVpLEnI2jFs2DCysrI4ceIEjY2NLFmyhKlTp1o6LGGEmpoaqqqqLv7+xx9/vOyEl7BNU6dOZfHixQAsXryYadOmWTgiYazWb94A33//vXx92gidTsf999/PgAEDeOKJJy5+XL42jSONYTuwdu1aHnvsMbRaLfPmzeO5556zdEjCCLm5uUyfPh2A5uZm7rzzTnkvbcwdd9zB1q1bKSsrIzAwkIULF3Lrrbcye/ZsTp8+Te/evVm2bJkUi9uAtt7LrVu3kpaWhkqlIiIigk8++eRiDZKwXikpKYwaNYqEhATs7JT1nb///e8kJyfL16YRJCETQgghhLAw2bIUQgghhLAwSciEEEIIISxMEjIhhBBCCAuThEwIIYQQwsIkIRNCCCGEsDBJyIQQPZa9vT2JiYkX/zPlkOOTJ09KvywhhMk4WDoAIYToLq6urqSlpVk6DCGE6JSskAkhrjoRERE8/fTTJCQkMHz4cLKzswFl1WvcuHEMHDiQ8ePHc/r0aUAZZD59+nQGDRrEoEGD2LVrFwBarZYHHniAuLg4Jk6cSF1dncVekxDCtklCJoToserq6i7bsly6dOnFz3l5eZGens7DDz/MY489BsAjjzzC3LlzOXToEHfddRePPvooAI8++ihjxozh4MGD7N+/n7i4OACysrJ46KGHOHLkCN7e3nz77bfmf5FCiB5BOvULIXosDw8Pqqurf/XxiIgINm/eTJ8+fWhqakKj0VBeXo6fnx+FhYU4OjrS1NREUFAQZWVl+Pv7k5+fj7Oz88VrnDx5kgkTJpCVlQXAa6+9RlNTE88//7zZXp8QoueQFTIhxFVJpVK1+XtDXJqg2dvb09zc3OW4hBBXJ0nIhBBXpdbty6VLl3LttdcCMGLECJYsWQLAf//7X0aNGgXA+PHj+eijjwClbqyystICEQshejI5ZSmE6LFaa8ha3XTTTRdbX5w9e5aBAwfi7OzM119/DcA///lP7rvvPt544w38/f354osvAHj33XeZP38+n3/+Ofb29nz00UcEBQWZ/wUJIXosqSETQlx1IiIiSE1Nxc/Pz9KhCCEEIFuWQgghhBAWJytkQgghhBAWJitkQgghhBAWJgmZEEIIIYSFSUImhBBCCGFhkpAJIYQQQliYJGRCCCGEEBYmCZkQQgghhIX9f47vt7tjoLrGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6ww2lt6paB4_"
      },
      "source": [
        "### 4.2 Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1KZ7WVqhaB4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8541f3ca-478b-4c81-9c1a-9a7fafbbec1c"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "# print(batch_size)\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # print(images.size())\n",
        "\n",
        "    # If current batch matches batch_size, just do the usual thing\n",
        "    if images.size()[0] == batch_size:\n",
        "      outputs, _ = net(images.view(batch_size, -1))\n",
        "      # outputs, _ = net(images.view(batch_size, 1, 28, 28))\n",
        "\n",
        "    # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "    # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "    else:\n",
        "      temp_bs = batch_size\n",
        "      batch_size = images.size()[0]\n",
        "      outputs, _ = net(images.view(images.size()[0], -1))\n",
        "      # outputs, _ = net(images.view(images.size()[0], 1, 28, 28))\n",
        "      batch_size = temp_bs\n",
        "\n",
        "    _, predicted = outputs.sum(dim=0).max(1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "print(f\"Test Set Accuracy: {100 * correct / total}%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total correctly classified test set images: 1180/10000\n",
            "Test Set Accuracy: 11.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0mLwBng9fhkn"
      },
      "source": [
        "def Binarize(tensor):\n",
        "    tensor[tensor > 0] = 1\n",
        "    tensor[tensor == 0] = 0\n",
        "    tensor[tensor < 0] = -1\n",
        "    return tensor\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#     # initialize layers\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.fc2 = nn.Linear(64*5*5, 10, bias= False)\n",
        "#         self.lif3 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF state variables and spike output tensors\n",
        "#         spk1, syn1, mem1 = self.lif1.init_stein(batch_size, 12, 13, 13)\n",
        "#         spk2, syn2, mem2 = self.lif1.init_stein(batch_size, 64, 5, 5)\n",
        "#         spk3, syn3, mem3 = self.lif2.init_stein(batch_size, 10)\n",
        "\n",
        "#         spk3_rec = []\n",
        "#         mem3_rec = []\n",
        "\n",
        "#         for step in range(num_steps):\n",
        "#             conv1_bin_weight = self.conv1.weight.data.clone()\n",
        "#             self.conv1.weight.data = Binarize(conv1_bin_weight)\n",
        "            \n",
        "#             # cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "#             cur1 = F.max_pool2d(F.conv2d(x, self.conv1.weight, bias=None, stride=1,\n",
        "#                                    padding=1), 2)\n",
        "            \n",
        "#             spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "#             conv2_bin_weight = self.conv2.weight.data.clone()\n",
        "#             self.conv2.weight.data = Binarize(conv2_bin_weight)\n",
        "\n",
        "#             # cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "#             cur2 = F.max_pool2d(F.conv2d(spk1, self.conv2.weight, bias=None, stride=1,\n",
        "#                                    padding=1), 2)\n",
        "            \n",
        "#             spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "#             fc_bin_weight = self.fc2.weight.data.clone()\n",
        "#             self.fc2.weight.data = Binarize(fc_bin_weight)\n",
        "\n",
        "#             # cur3 = self.fc2(spk2.view(batch_size, -1))\n",
        "#             cur3 = F.linear(spk2.view(batch_size, -1), self.fc2.weight)\n",
        "#             spk3, syn3, mem3 = self.lif3(cur3, syn3, mem3)\n",
        "\n",
        "#             spk3_rec.append(spk3)\n",
        "#             mem3_rec.append(mem3)\n",
        "\n",
        "#         return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# net = Net().to(device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
        "        self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
        "        self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            fc1_bin_weight = self.fc1.weight.data.clone()\n",
        "            self.fc1.weight.data = Binarize(fc1_bin_weight)\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "            fc2_bin_weight = self.fc2.weight.data.clone()\n",
        "            self.fc2.weight.data = Binarize(fc2_bin_weight)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "            # print(spk2.shape)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "g5y4NZAgaB49",
        "outputId": "68e0e0ec-0a40-4682-c014-a17fc8258d23"
      },
      "source": [
        "Old Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ghbg4Ga2fhkq"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(4):\n",
        "\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        output, mem_rec = net(data_it.view(batch_size, -1))\n",
        "        # output, mem_rec = net(data_it.view(batch_size, 1, 28, 28)) # [28x28] or [1x28x28]?\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # Gradient calculation\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward(retain_graph=True)\n",
        "\n",
        "        # Weight Update\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(testdata_it.view(batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(testdata_it.view(batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "          train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hDQg3UsUaB4_"
      },
      "source": [
        "Voila! That's it for static MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Rh7ZwFs4aB4_"
      },
      "source": [
        "## 5. Spiking MNIST\n",
        "Part of the appeal of SNNs is their ability to handle time-varying spiking data. So let's use rate-coding to convert MNIST into spiking MNIST using the `spikegen` module in Tutorial 1, and train our network with that instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DYGblNEgaB5A"
      },
      "source": [
        "from snntorch import spikegen\n",
        "\n",
        "# MNIST to spiking-MNIST\n",
        "# spike_data, spike_targets = spikegen.latency(data_it, targets = targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "#                                                       gain=1, offset=0, convert_targets=True, temporal_targets=True)\n",
        "data_it = torch.round(data_it * 32)\n",
        "spike_data = torch.zeros(num_steps, batch_size, 784)\n",
        "spike_data[data_it, ]\n",
        "spike_data, spike_targets = spikegen.latency(data_it, targets = targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                      convert_targets=True, temporal_targets=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xgRdm4jRaB5A"
      },
      "source": [
        "### 5.1 Visualiser\n",
        "Just so you're damn sure it's a spiking input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "geVqzyksaB5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923ddf47-c6c6-4cc4-a4fc-10af9ab9d3e1"
      },
      "source": [
        "!pip install celluloid # animating matplotlib plots made easy"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting celluloid\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a7/7fbe80721c6f1b7370c4e50c77abe31b4d5cfeb58873d4d32f48ae5a0bae/celluloid-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from celluloid) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->celluloid) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->celluloid) (1.15.0)\n",
            "Installing collected packages: celluloid\n",
            "Successfully installed celluloid-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PbLMA0pgaB5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdffa8b0-7b4a-46d5-cc6b-fc68936b068e"
      },
      "source": [
        "from celluloid import Camera\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Animator\n",
        "spike_data_sample = spike_data[:, 0, 0].cpu()\n",
        "# index = torch.argmax(spike_data_sample, dim=(1, 2))\n",
        "print(sum((spike_data_sample[3])))\n",
        "print((spike_data_sample[1]).size())\n",
        "fig, ax = plt.subplots()\n",
        "camera = Camera(fig)\n",
        "plt.axis('off')\n",
        "print((data_it[0,0]))\n",
        "for step in range(1):\n",
        "    # im = ax.imshow(spike_data_sample[step, :, :], cmap='plasma')\n",
        "    im = ax.imshow(data_it[0,0], cmap='plasma')\n",
        "    camera.snap()\n",
        "\n",
        "# interval=40 specifies 40ms delay between frames\n",
        "a = camera.animate(interval=40)\n",
        "HTML(a.to_html5_video())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n",
            "torch.Size([28, 28])\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0941, 0.1843, 0.5412, 0.5882, 0.9333, 0.9961, 1.0000, 0.9294, 0.4510,\n",
            "         0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5686,\n",
            "         0.8863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "         0.8784, 0.4863, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.8784,\n",
            "         0.9922, 0.9529, 0.8510, 0.8510, 0.8510, 0.8510, 0.8510, 0.8745, 0.9922,\n",
            "         0.9922, 0.9922, 0.4941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.8863,\n",
            "         0.4627, 0.1882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.4039,\n",
            "         0.9765, 0.9922, 0.8314, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 0.8353,\n",
            "         0.3020, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.1255, 0.6392, 0.9922, 0.8314, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490, 0.9922,\n",
            "         0.9922, 0.7843, 0.6902, 0.5255, 0.6824, 0.4549, 0.2863, 0.0078, 0.0000,\n",
            "         0.0000, 0.0941, 0.8078, 0.9922, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3529, 0.9529,\n",
            "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.5647, 0.0000,\n",
            "         0.0000, 0.0000, 0.2980, 0.9922, 0.5451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137,\n",
            "         0.7176, 0.7490, 0.7490, 0.7490, 0.8549, 0.9922, 0.9922, 0.8314, 0.0000,\n",
            "         0.0000, 0.0000, 0.0314, 0.7843, 0.5451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.3333, 0.9922, 0.4902, 0.0000,\n",
            "         0.0000, 0.0000, 0.0353, 0.8039, 0.2078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 0.9922, 0.4275, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.2627, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3647, 0.9922, 0.1020, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6118, 0.9922, 0.0196, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9020, 0.9922, 0.0196, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.6275, 0.0039, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.3176, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.2000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.3098, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.2588, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.4627, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0784, 0.5137, 0.6078, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAIoG1kYXQAAAKuBgX//6rcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MyBsb29r\n",
              "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
              "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
              "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
              "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
              "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
              "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAXiZYiE\n",
              "ACv//vZzfAprRzOVLgV292aj5dCS5fsQYPrQAAADAAGq07IMpSasR30AADksYA6OEZBgADeh2xrJ\n",
              "0euSfCZLWjeyV2Y685tiXvhDDWEqHXCW8J/6LYTVdB5qYDL+T/8vVX7Qhs9o68aR17IdPwBZwadw\n",
              "iY7oDd6ZbPaRivjrodC87kCjyEo7J8zezqeur+iWgRD1da7bUKduu6HV8HKCSngXPmuMZ5Bjz6OU\n",
              "xaEgyZsjrm5QQp2+DbkhAkokupKgVwqEIMgIFlzDOypHmlKkQN0Xa7Hx/37vYgMIkAvitbF4iQc8\n",
              "U3mzpltOjbSlzHHATxPJEDCXREfOKcWJRy7bUQREsnFU+KLhvRPsWImuo2AvPCiqyk+qzyw82u5n\n",
              "eTTePL2bVrnfh2jMDwLB4oya8M/idjhx3nkwxQXOAzLji8FYpR9GCDIie7LgQtuT7yN/+kOyGnpB\n",
              "dJVr2hzYwLjLtk9Dk+PCRpM6rRUbzwguYusH8mnsHkcYRE3FKYawXakAQVFHJvYoJG/upZEcyLfD\n",
              "sT8sws6/PMhicomFH9VW66BsspP2Eqa9Au/Dlkrbc9y6MSAQDRz+Cfd0GUPaQ58fKBaI08Pseh85\n",
              "tzyc0h/et6xwSyL7Sfb2jKoUOYdmzdiHDsuNpgKHLf5BdOuXUdq6IX0DBMXddAYiSqjQD0IoUbCF\n",
              "EmW8ekr4rrIepvxKlNz2WCyXyv3l970niPi3ZOWOCdpidMJegwYA7Yhc5N7pWajsOG/rAU7ZEpOM\n",
              "6RTWgeiCy7iCtfl8FgVYaBKYsSl2+x/4XeAEDVA/qc8bsZX9H+fibKsonGhIyZmuspuT0JCSYANL\n",
              "CmLvEyRvyL+d8kA279WAK4CwkJIhRzfYpvrbT49ellPGmwzJZ3GmZFYI4n0ABcR3ZNKeEbPQaNXt\n",
              "9srSDgSbDSQLiRKRdnQLdgzRI3G3IlKBdmYzAIwhQwiMtOC6Z/SGE152G4bvQD5hJuWVNTdrrb9w\n",
              "ZKFdk5txPhvJYgt5I3ow6Jm08RFC+kyi5w0sJWCby6weIvaZ2FY4HDPNxjyqGL8I3ZNZqhohsgeI\n",
              "cMoO4cOdc5XFPhG2BN1Bp01Ai3n2boLYMl8kZG3R3TQLZAJXsxV8FCYz4kUAV+3nrVe4jGfvSHoT\n",
              "foyV/4Y1mlkXBngoq7MVrEvlEAoLrIaAvDK9WAm6JFtZIdvnRtE3N5piqWKL7ZZCiaDpD41LjEv3\n",
              "PpER5I0w1pz+7eDjZP7MArs+xAfz+zDmFU/f8CgYt++MuRDU5h/cQLeWmgAqI+G1Q3sKa0ykr5QP\n",
              "bcqwogkBtMai1m+JikQ5F2Xzrhh/JOIRyFxQ9+pinU5IjGBThzxXU5v3rI7mOfaMKGhlVlhsaBSi\n",
              "kGzdFojqyTnomWPPzLVS/FYrWP74+nBDERTkmovvm9zWW7k09X4pMEaCMg4A7C7Zgm7fWIkWJR5a\n",
              "/ssQYFXqucOaZypy15oSQPD5h2X9E6BegFIrxqhzccv756DUxmsMi18jfpd93X2BlaA5BuGmwbfk\n",
              "mObYkQrp+D/pkXXFOPWkyewyXEhgDecu+GIDHzk5zvEIKFWGy5iQ0je/xKY6zSMYQFGoF+JGI+Qy\n",
              "TGKpjYe+Fhdw5VgPUYKpr/sPh5PtHlz5oyTQE82qjyjkEiq3tcRwT9xm5bkNzlmDbsy5azh/VH/y\n",
              "8CB10sfp25sjHk3NEQnO/M3/6Ej9MCpaqzyGIXqH4xpFIuFEGVFIOUfMjQAme5BGjXwbyC5prRyj\n",
              "RFOvKzwKisO6g68JW67oKwcWF/2N0nk9pgOk45ovDKD0Q/Sa+zzxCZ48WjFg6YALpO7eNeyhBvYq\n",
              "y0pe5RQmm5ZVZb91+Jhpu3dwcFyuyLqlU1QCJRiUPzOF7HbMAzQ2W63wKDGvt7VOmboIlOAG9cKp\n",
              "gymEEhSWfc9Pd+1UEMIF5eB6hKF2olKXjkIl0Nt76f1BbA9lYydHv79KqOV73HDEqswJxN/B4Wyk\n",
              "tCgA4/wFQq9EliDIowAABTY34H9BAAADCm1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAAo\n",
              "AAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAI0dHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAA\n",
              "AAAAAAAoAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAA\n",
              "AAGwAAABIAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAAKAAAAAAAAQAAAAABrG1kaWEAAAAg\n",
              "bWRoZAAAAAAAAAAAAAAAAAAAMgAAAAIAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAA\n",
              "AAAAVmlkZW9IYW5kbGVyAAAAAVdtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxk\n",
              "cmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAEXc3RibAAAALNzdHNkAAAAAAAAAAEAAACjYXZjMQAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAAGwASAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAAAAAAAABj//wAAADFhdmNDAWQAFf/hABhnZAAVrNlBsJaEAAADAAQAAAMAyDxY\n",
              "tlgBAAZo6+PLIsAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAA\n",
              "AAEAAAIAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAABAAAAAQAAABRzdHN6AAAAAAAACJgAAAABAAAA\n",
              "FHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGly\n",
              "YXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3LjgzLjEw\n",
              "MA==\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAACtklEQVR4nO3TMQEAIAzAMMC/52GAnx6Jgj7dM7OAnvM7AHgzJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNClDkhypwQZU6IMidEmROizAlR5oQoc0KUOSHKnBBlTogyJ0SZE6LMCVHmhChzQpQ5IcqcEGVOiDInRJkToswJUeaEKHNC1AVcegTL+uSnUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tWw9n9H0aB5A"
      },
      "source": [
        "## 6. Define Network\n",
        "The network is the same as before. The one difference is that the for-loop iterates through the first dimension of the input:\n",
        "`cur1 = F.max_pool2d(self.conv1(x[step]), 2)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9rOLmqFPjc5k"
      },
      "source": [
        "### Binarized Layer Modules\n",
        "``Binarize`` converts weights to {-1, 1}.\n",
        "Remove `.mul_(2).add_(1)` for {0, 1}."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7Z92BOo4j7Ul"
      },
      "source": [
        "import pdb\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def Binarize(tensor,quant_mode='det'):\n",
        "    if quant_mode=='det':\n",
        "        return tensor.sign()\n",
        "        # tmp = tensor.clone()\n",
        "        # tmp[tensor>0] = 1\n",
        "        # tmp[tensor==0] = 0\n",
        "        # tmp[tensor<0] = -1\n",
        "        # return tmp\n",
        "    else:\n",
        "        return tensor.add_(1).div_(2).add_(torch.rand(tensor.size()).add(-0.5)).clamp_(0,1).round().mul_(2).add_(-1)\n",
        "\n",
        "\n",
        "class HingeLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HingeLoss,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def hinge_loss(self,input,target):\n",
        "            #import pdb; pdb.set_trace()\n",
        "            output=self.margin-input.mul(target)\n",
        "            output[output.le(0)]=0\n",
        "            return output.mean()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.hinge_loss(input,target)\n",
        "\n",
        "class SqrtHingeLossFunction(Function):\n",
        "    def __init__(self):\n",
        "        super(SqrtHingeLossFunction,self).__init__()\n",
        "        self.margin=1.0\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        output=self.margin-input.mul(target)\n",
        "        output[output.le(0)]=0\n",
        "        self.save_for_backward(input, target)\n",
        "        loss=output.mul(output).sum(0).sum(1).div(target.numel())\n",
        "        return loss\n",
        "\n",
        "    def backward(self,grad_output):\n",
        "       input, target = self.saved_tensors\n",
        "       output=self.margin-input.mul(target)\n",
        "       output[output.le(0)]=0\n",
        "       import pdb; pdb.set_trace()\n",
        "       grad_output.resize_as_(input).copy_(target).mul_(-2).mul_(output)\n",
        "       grad_output.mul_(output.ne(0).float())\n",
        "       grad_output.div_(input.numel())\n",
        "       return grad_output,grad_output\n",
        "\n",
        "def Quantize(tensor,quant_mode='det',  params=None, numBits=8):\n",
        "    tensor.clamp_(-2**(numBits-1),2**(numBits-1))\n",
        "    if quant_mode=='det':\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().div(2**(numBits-1))\n",
        "    else:\n",
        "        tensor=tensor.mul(2**(numBits-1)).round().add(torch.rand(tensor.size()).add(-0.5)).div(2**(numBits-1))\n",
        "        quant_fixed(tensor, params)\n",
        "    return tensor\n",
        "\n",
        "# import torch.nn._functions as tnnf\n",
        "\n",
        "\n",
        "class BinarizeLinear(nn.Linear):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if input.size(1) != 784:\n",
        "            input.data=Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "        out = nn.functional.linear(input, self.weight)\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1).expand_as(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BinarizeConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeConv2d, self).__init__(*kargs, **kwargs)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        if input.size(1) != 3:\n",
        "            input.data = Binarize(input.data)\n",
        "        if not hasattr(self.weight,'org'):\n",
        "            self.weight.org=self.weight.data.clone()\n",
        "        self.weight.data=Binarize(self.weight.org)\n",
        "\n",
        "        out = nn.functional.conv2d(input, self.weight, None, self.stride,\n",
        "                                   self.padding, self.dilation, self.groups)\n",
        "\n",
        "        if not self.bias is None:\n",
        "            self.bias.org=self.bias.data.clone()\n",
        "            out += self.bias.view(1, -1, 1, 1).expand_as(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QO_sFhGsj_9Y"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        # self.bn0 = nn.BatchNorm1d(784)\n",
        "        self.fc1 = BinarizeLinear(784, num_hidden)\n",
        "        self.lif1 = Stein_single(alpha=alpha, beta=beta)\n",
        "\n",
        "        self.fc2 = BinarizeLinear(num_hidden, num_outputs)\n",
        "        self.lif2 = Stein_single(alpha=alpha, beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            mask_x = torch.zeros_like(x[step])\n",
        "            index = torch.argmax(x[step], dim=-1)\n",
        "            mask_x[torch.arange(x[step].size()[0]), index] = 1\n",
        "            x_in = (x[step] * mask_x).to(device)\n",
        "            cur1 = self.fc1(x_in)\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nzpf57Q1aB5B"
      },
      "source": [
        "## 7. Training\n",
        "We make a slight modification to our print-out functions to handle the new first dimension of the input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w1saOFIFaB5B"
      },
      "source": [
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    output, _ = net(data.view(num_steps, batch_size, -1))\n",
        "    # output, _ = net(data.view(num_steps, batch_size, 1, 28, 28))\n",
        "    _, idx = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "    if train:\n",
        "        print(f\"Train Set Accuracy: {acc}\")\n",
        "    else:\n",
        "        print(f\"Test Set Accuracy: {acc}\")\n",
        "\n",
        "def train_printer():\n",
        "    print(f\"Epoch {epoch}, Minibatch {minibatch_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]}\")\n",
        "    print_batch_accuracy(spike_data, spike_targets, train=True)\n",
        "    print_batch_accuracy(test_spike_data, test_spike_targets, train=False)\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V9qnIq0MaB5B"
      },
      "source": [
        "### 7.1 Optimizer & Loss\n",
        "We'll keep our optimizer and loss the exact same as the static MNIST case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KeWZQlzEaB5B"
      },
      "source": [
        "lr = 2e-3\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VCHfUz7waB5C"
      },
      "source": [
        "### 7.2 Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "H_P1ffX-kIvR"
      },
      "source": [
        "High precision BPTT training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "noSeE-t4kN33",
        "outputId": "59ca57eb-e67f-45a3-da18-d4031517a03c"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    new_lr = lr * (0.85 ** epoch)\n",
        "    # lr = lr\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_lr\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(10):\n",
        "\n",
        "    minibatch_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in train_batch:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        # Spike generator\n",
        "        spike_data, spike_targets = spikegen.rate(data_it, targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                  gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "        \n",
        "\n",
        "        # Forward pass\n",
        "        output, mem_rec = net(spike_data.view(num_steps, batch_size, -1))\n",
        "        # output, mem_rec = net(spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "        \n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # BNN OPTimization\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.data.copy_(p.org)\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        for p in list(net.parameters()):\n",
        "                if hasattr(p,'org'):\n",
        "                    p.org.copy_(p.data.clamp_(-1,1))\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set spike conversion\n",
        "        test_spike_data, test_spike_targets = spikegen.rate(testdata_it, testtargets_it, num_outputs=num_outputs,\n",
        "                                                            num_steps=num_steps, gain=1, offset=0, convert_targets=False,\n",
        "                                                            temporal_targets=False)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, testtargets_it)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "          train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      for data in test_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # If current batch matches batch_size, just do the usual thing\n",
        "        if images.size()[0] == batch_size:\n",
        "          spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                                gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "          outputs, _ = net(spike_test.view(num_steps, batch_size, -1))\n",
        "          # outputs, _ = net(spike_test.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "        # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "        # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "        else:\n",
        "          temp_bs = batch_size\n",
        "          batch_size = images.size()[0]\n",
        "          spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                                gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "          outputs, _ = net(spike_test.view(num_steps, images.size()[0], -1))\n",
        "          # outputs, _ = net(spike_test.view(num_steps, images.size()[0], 1, 28, 28))\n",
        "          batch_size = temp_bs\n",
        "\n",
        "        _, predicted = outputs.sum(dim=0).max(1)\n",
        "        total += spike_targets.size(0)\n",
        "        correct += (predicted == spike_targets).sum().item()\n",
        "\n",
        "    print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "    print(f\"Test Set Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "    \n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Minibatch 0\n",
            "Train Set Loss: 90.48095703125\n",
            "Test Set Loss: 91.45067596435547\n",
            "Train Set Accuracy: 0.109375\n",
            "Test Set Accuracy: 0.078125\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 50\n",
            "Train Set Loss: 75.22721099853516\n",
            "Test Set Loss: 72.23780822753906\n",
            "Train Set Accuracy: 0.2890625\n",
            "Test Set Accuracy: 0.2890625\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 100\n",
            "Train Set Loss: 70.15290832519531\n",
            "Test Set Loss: 64.23790740966797\n",
            "Train Set Accuracy: 0.3984375\n",
            "Test Set Accuracy: 0.4375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 150\n",
            "Train Set Loss: 62.63232421875\n",
            "Test Set Loss: 63.495826721191406\n",
            "Train Set Accuracy: 0.4453125\n",
            "Test Set Accuracy: 0.359375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 200\n",
            "Train Set Loss: 63.01062774658203\n",
            "Test Set Loss: 62.97613525390625\n",
            "Train Set Accuracy: 0.453125\n",
            "Test Set Accuracy: 0.40625\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 250\n",
            "Train Set Loss: 62.69618225097656\n",
            "Test Set Loss: 61.12319564819336\n",
            "Train Set Accuracy: 0.375\n",
            "Test Set Accuracy: 0.359375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 300\n",
            "Train Set Loss: 63.45652389526367\n",
            "Test Set Loss: 60.522117614746094\n",
            "Train Set Accuracy: 0.4296875\n",
            "Test Set Accuracy: 0.46875\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 350\n",
            "Train Set Loss: 64.68856811523438\n",
            "Test Set Loss: 59.24117660522461\n",
            "Train Set Accuracy: 0.3984375\n",
            "Test Set Accuracy: 0.3984375\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 400\n",
            "Train Set Loss: 61.41581344604492\n",
            "Test Set Loss: 57.300689697265625\n",
            "Train Set Accuracy: 0.4140625\n",
            "Test Set Accuracy: 0.421875\n",
            "\n",
            "\n",
            "Epoch 0, Minibatch 450\n",
            "Train Set Loss: 59.65199279785156\n",
            "Test Set Loss: 58.382789611816406\n",
            "Train Set Accuracy: 0.421875\n",
            "Test Set Accuracy: 0.4296875\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 4141/10000\n",
            "Test Set Accuracy: 41.41%\n",
            "Epoch 1, Minibatch 32\n",
            "Train Set Loss: 55.67587661743164\n",
            "Test Set Loss: 58.84961700439453\n",
            "Train Set Accuracy: 0.453125\n",
            "Test Set Accuracy: 0.421875\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 82\n",
            "Train Set Loss: 62.778099060058594\n",
            "Test Set Loss: 57.07685089111328\n",
            "Train Set Accuracy: 0.4140625\n",
            "Test Set Accuracy: 0.4375\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 132\n",
            "Train Set Loss: 57.42074203491211\n",
            "Test Set Loss: 54.75466537475586\n",
            "Train Set Accuracy: 0.3671875\n",
            "Test Set Accuracy: 0.5\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 182\n",
            "Train Set Loss: 61.05434036254883\n",
            "Test Set Loss: 58.75154113769531\n",
            "Train Set Accuracy: 0.3359375\n",
            "Test Set Accuracy: 0.421875\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 232\n",
            "Train Set Loss: 57.88541793823242\n",
            "Test Set Loss: 62.401912689208984\n",
            "Train Set Accuracy: 0.40625\n",
            "Test Set Accuracy: 0.328125\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 282\n",
            "Train Set Loss: 54.66345977783203\n",
            "Test Set Loss: 56.84615707397461\n",
            "Train Set Accuracy: 0.4375\n",
            "Test Set Accuracy: 0.3515625\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 332\n",
            "Train Set Loss: 57.531280517578125\n",
            "Test Set Loss: 58.35578155517578\n",
            "Train Set Accuracy: 0.484375\n",
            "Test Set Accuracy: 0.3828125\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 382\n",
            "Train Set Loss: 60.06085968017578\n",
            "Test Set Loss: 58.48374557495117\n",
            "Train Set Accuracy: 0.359375\n",
            "Test Set Accuracy: 0.4140625\n",
            "\n",
            "\n",
            "Epoch 1, Minibatch 432\n",
            "Train Set Loss: 58.881439208984375\n",
            "Test Set Loss: 58.721012115478516\n",
            "Train Set Accuracy: 0.4140625\n",
            "Test Set Accuracy: 0.4296875\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 3298/10000\n",
            "Test Set Accuracy: 32.98%\n",
            "Epoch 2, Minibatch 14\n",
            "Train Set Loss: 59.41498565673828\n",
            "Test Set Loss: 58.343936920166016\n",
            "Train Set Accuracy: 0.328125\n",
            "Test Set Accuracy: 0.3984375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 64\n",
            "Train Set Loss: 55.99372863769531\n",
            "Test Set Loss: 59.09606170654297\n",
            "Train Set Accuracy: 0.359375\n",
            "Test Set Accuracy: 0.359375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 114\n",
            "Train Set Loss: 57.61301803588867\n",
            "Test Set Loss: 57.70578384399414\n",
            "Train Set Accuracy: 0.3984375\n",
            "Test Set Accuracy: 0.375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 164\n",
            "Train Set Loss: 57.834800720214844\n",
            "Test Set Loss: 58.0894889831543\n",
            "Train Set Accuracy: 0.421875\n",
            "Test Set Accuracy: 0.390625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 214\n",
            "Train Set Loss: 58.906314849853516\n",
            "Test Set Loss: 60.39836883544922\n",
            "Train Set Accuracy: 0.359375\n",
            "Test Set Accuracy: 0.34375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 264\n",
            "Train Set Loss: 57.1186637878418\n",
            "Test Set Loss: 58.861236572265625\n",
            "Train Set Accuracy: 0.3359375\n",
            "Test Set Accuracy: 0.40625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 314\n",
            "Train Set Loss: 59.815185546875\n",
            "Test Set Loss: 54.677913665771484\n",
            "Train Set Accuracy: 0.3515625\n",
            "Test Set Accuracy: 0.4375\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 364\n",
            "Train Set Loss: 55.71723937988281\n",
            "Test Set Loss: 55.253517150878906\n",
            "Train Set Accuracy: 0.4296875\n",
            "Test Set Accuracy: 0.40625\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 414\n",
            "Train Set Loss: 62.809471130371094\n",
            "Test Set Loss: 60.706153869628906\n",
            "Train Set Accuracy: 0.3984375\n",
            "Test Set Accuracy: 0.3203125\n",
            "\n",
            "\n",
            "Epoch 2, Minibatch 464\n",
            "Train Set Loss: 59.6370735168457\n",
            "Test Set Loss: 54.829498291015625\n",
            "Train Set Accuracy: 0.296875\n",
            "Test Set Accuracy: 0.375\n",
            "\n",
            "\n",
            "Total correctly classified test set images: 3476/10000\n",
            "Test Set Accuracy: 34.76%\n",
            "Epoch 3, Minibatch 46\n",
            "Train Set Loss: 59.480690002441406\n",
            "Test Set Loss: 59.889556884765625\n",
            "Train Set Accuracy: 0.3515625\n",
            "Test Set Accuracy: 0.34375\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 96\n",
            "Train Set Loss: 57.64363479614258\n",
            "Test Set Loss: 59.29077911376953\n",
            "Train Set Accuracy: 0.4453125\n",
            "Test Set Accuracy: 0.3828125\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 146\n",
            "Train Set Loss: 57.57373809814453\n",
            "Test Set Loss: 57.62171936035156\n",
            "Train Set Accuracy: 0.3828125\n",
            "Test Set Accuracy: 0.3515625\n",
            "\n",
            "\n",
            "Epoch 3, Minibatch 196\n",
            "Train Set Loss: 58.87971878051758\n",
            "Test Set Loss: 60.38278579711914\n",
            "Train Set Accuracy: 0.2734375\n",
            "Test Set Accuracy: 0.296875\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1a8d534a684a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Test set forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mem_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_spike_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, 1, 28, 28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1d3a614775ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcur1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mcur2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mspk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2bbc77f64e11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2bbc77f64e11>\u001b[0m in \u001b[0;36mfire_single\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# print(index.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmask_spk1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mspk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspk_tmp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_spk1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# print(spk[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nVldb0Q9aB5C"
      },
      "source": [
        "## 8. Spiking MNIST Results\n",
        "### 8.1 Plot Training/Test Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XopHe17ZaB5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "644d0ce3-a25c-48d7-99b3-3578cefc4586"
      },
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "plt.plot(loss_hist)\n",
        "plt.plot(test_loss_hist)\n",
        "plt.legend([\"Test Loss\", \"Train Loss\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lgu-tzsfaB5C"
      },
      "source": [
        "### 8.2 Test Set Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nyIVun6laB5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e612a189-ba1c-4bda-b43b-ac79d9630eca"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # If current batch matches batch_size, just do the usual thing\n",
        "    if images.size()[0] == batch_size:\n",
        "      spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                            gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "      outputs, _ = net(spike_test.view(num_steps, batch_size, -1))\n",
        "      # outputs, _ = net(spike_test.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "    # If current batch does not match batch_size (e.g., is the final minibatch),\n",
        "    # modify batch_size in a temp variable and restore it at the end of the else block\n",
        "    else:\n",
        "      temp_bs = batch_size\n",
        "      batch_size = images.size()[0]\n",
        "      spike_test, spike_targets = spikegen.rate(images, labels, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                            gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "      outputs, _ = net(spike_test.view(num_steps, images.size()[0], -1))\n",
        "      # outputs, _ = net(spike_test.view(num_steps, images.size()[0], 1, 28, 28))\n",
        "      batch_size = temp_bs\n",
        "\n",
        "    _, predicted = outputs.sum(dim=0).max(1)\n",
        "    total += spike_targets.size(0)\n",
        "    correct += (predicted == spike_targets).sum().item()\n",
        "\n",
        "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "print(f\"Test Set Accuracy: {100 * correct / total}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total correctly classified test set images: 9510/10000\n",
            "Test Set Accuracy: 95.1%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fuzanqrCaB5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "49fec2d5-6aaf-4bc2-9f36-1dffff939b32"
      },
      "source": [
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(1):\n",
        "    minibatch_counter = 0\n",
        "    data = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data_it, targets_it in data:\n",
        "        data_it = data_it.to(device)\n",
        "        targets_it = targets_it.to(device)\n",
        "\n",
        "        # Spike generator\n",
        "        spike_data, spike_targets = spikegen.rate(data_it, targets_it, num_outputs=num_outputs, num_steps=num_steps,\n",
        "                                                  gain=1, offset=0, convert_targets=False, temporal_targets=False)\n",
        "\n",
        "        # Forward pass\n",
        "        output, mem_rec = net(spike_data.view(num_steps, batch_size, -1))\n",
        "        # output, mem_rec = net(spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "        log_p_y = log_softmax_fn(mem_rec)\n",
        "        loss_val = torch.zeros(1, dtype=dtype, device=device)\n",
        "\n",
        "        # Sum loss over time steps to perform BPTT\n",
        "        for step in range(num_steps):\n",
        "          loss_val += loss_fn(log_p_y[step], targets_it)\n",
        "\n",
        "        # Gradient Calculation\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward(retain_graph=True)\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "\n",
        "        # Weight Update\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store Loss history\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        test_data = itertools.cycle(test_loader)\n",
        "        testdata_it, testtargets_it = next(test_data)\n",
        "        testdata_it = testdata_it.to(device)\n",
        "        testtargets_it = testtargets_it.to(device)\n",
        "\n",
        "        # Test set spike conversion\n",
        "        test_spike_data, test_spike_targets = spikegen.rate(testdata_it, testtargets_it, num_outputs=num_outputs,\n",
        "                                                            num_steps=num_steps, gain=1, offset=0, convert_targets=False,\n",
        "                                                            temporal_targets=False)\n",
        "\n",
        "        # Test set forward pass\n",
        "        test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, -1))\n",
        "        # test_output, test_mem_rec = net(test_spike_data.view(num_steps, batch_size, 1, 28, 28))\n",
        "\n",
        "        # Test set loss\n",
        "        log_p_ytest = log_softmax_fn(test_mem_rec)\n",
        "        log_p_ytest = log_p_ytest.sum(dim=0)\n",
        "        loss_val_test = loss_fn(log_p_ytest, test_spike_targets)\n",
        "        test_loss_hist.append(loss_val_test.item())\n",
        "\n",
        "        # Print test/train loss/accuracy\n",
        "        if counter % 50 == 0:\n",
        "            train_printer()\n",
        "        minibatch_counter += 1\n",
        "        counter += 1\n",
        "\n",
        "loss_hist_true_grad = loss_hist\n",
        "test_loss_hist_true_grad = test_loss_hist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Minibatch 0\n",
            "Train Set Loss: 17.53070068359375\n",
            "Test Set Loss: 19.592514038085938\n",
            "Train Set Accuracy: 0.8359375\n",
            "Test Set Accuracy: 0.796875\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-00bc68d644bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# output, mem_rec = net(spike_data.view(num_steps, batch_size, 1, 28, 28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlog_p_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_softmax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_rec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-9bfae6026904>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcur2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mspk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlif2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mspk2_rec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/snntorch/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0msyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/snntorch/__init__.py\u001b[0m in \u001b[0;36mfire\u001b[0;34m(self, mem)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mspk_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmem_shift\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mreset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspk_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspk_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zIpvq5jdaB5B"
      },
      "source": [
        "# spike_fn = FSS.apply\n",
        "# snn.neuron.slope = 50\n",
        "spike_grad = snn.FastSigmoidSurrogate.apply\n",
        "snn.slope = 50\n",
        "\n",
        "def Binarize(tensor):\n",
        "    tensor[tensor > 0] = 1\n",
        "    tensor[tensor<=0] = 0\n",
        "    return tensor\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#     # initialize layers\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=5, stride=1, padding=1, bias=False)\n",
        "#         self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.fc2 = nn.Linear(64*5*5, 10, bias= False)\n",
        "#         self.lif3 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF state variables and spike output tensors\n",
        "#         spk1, syn1, mem1 = self.lif1.init_stein(batch_size, 12, 13, 13)\n",
        "#         spk2, syn2, mem2 = self.lif1.init_stein(batch_size, 64, 5, 5)\n",
        "#         spk3, syn3, mem3 = self.lif2.init_stein(batch_size, 10)\n",
        "\n",
        "#         spk3_rec = []\n",
        "#         mem3_rec = []\n",
        "\n",
        "#         for step in range(num_steps):\n",
        "#             conv1_bin_weight = self.conv1.weight.data.clone()\n",
        "#             self.conv1.weight.data = Binarize(conv1_bin_weight)\n",
        "            \n",
        "#             cur1 = F.max_pool2d(self.conv1(x[step]), 2)\n",
        "#             # cur1 = F.max_pool2d(F.conv2d(x, self.conv1.weight, bias=None, stride=1,\n",
        "#             #                        padding=1), 2)\n",
        "            \n",
        "#             spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "#             conv2_bin_weight = self.conv2.weight.data.clone()\n",
        "#             self.conv2.weight.data = Binarize(conv2_bin_weight)\n",
        "\n",
        "#             cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "#             # cur2 = F.max_pool2d(F.conv2d(spk1, self.conv2.weight, bias=None, stride=1,\n",
        "#             #                        padding=1), 2)\n",
        "            \n",
        "#             spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "\n",
        "#             fc_bin_weight = self.fc2.weight.data.clone()\n",
        "#             self.fc2.weight.data = Binarize(fc_bin_weight)\n",
        "\n",
        "#             cur3 = self.fc2(spk2.view(batch_size, -1))\n",
        "#             # cur3 = F.linear(spk2.view(batch_size, -1), self.fc2.weight)\n",
        "#             spk3, syn3, mem3 = self.lif3(cur3, syn3, mem3)\n",
        "\n",
        "#             spk3_rec.append(spk3)\n",
        "#             mem3_rec.append(mem3)\n",
        "\n",
        "#         return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# net = Net().to(device)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden, bias=False)\n",
        "        self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs, bias=False)\n",
        "        self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        spk1, syn1, mem1 = self.lif1.init_stein(batch_size, num_hidden)\n",
        "        spk2, syn2, mem2 = self.lif2.init_stein(batch_size, num_outputs)\n",
        "\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            fc1_bin_weight = self.fc1.weight.data.clone()\n",
        "            self.fc1.weight.data = Binarize(fc1_bin_weight)\n",
        "            cur1 = self.fc1(x[step])\n",
        "            spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "\n",
        "            fc2_bin_weight = self.fc2.weight.data.clone()\n",
        "            self.fc2.weight.data = Binarize(fc2_bin_weight)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "            # print(spk2.shape)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "net = Net().to(device)\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # initialize layers\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "#         self.lif1 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=5, stride=1, padding=1)\n",
        "#         self.lif2 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "#         self.fc2 = nn.Linear(64*5*5, 10)\n",
        "#         self.lif3 = snn.Stein(alpha=alpha, beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "#         # self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=0)\n",
        "#         # self.lif1 = LIF(spike_fn=spike_fn, alpha=alpha, beta=beta)\n",
        "#         # self.fc1 = nn.Linear(26*26*3, 10)\n",
        "#         # self.lif2 = LIF(spike_fn=spike_fn, alpha=alpha, beta=beta)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize LIF state variables and spike output tensors\n",
        "#         spk1, syn1, mem1 = self.lif1.init_stein(batch_size, 12, 13, 13)\n",
        "#         spk2, syn2, mem2 = self.lif2.init_stein(batch_size, 64, 5, 5)\n",
        "#         spk3, syn3, mem3 = self.lif3.init_stein(batch_size, 10)\n",
        "\n",
        "#         spk3_rec = []\n",
        "#         mem3_rec = []\n",
        "\n",
        "#         for step in range(num_steps):\n",
        "#             cur1 = F.max_pool2d(self.conv1(x[step]), 2) # add max-pooling to membrane or spikes?\n",
        "#             spk1, syn1, mem1 = self.lif1(cur1, syn1, mem1)\n",
        "#             cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "#             spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
        "#             cur3 = self.fc2(spk2.view(batch_size, -1))\n",
        "#             spk3, syn3, mem3 = self.lif3(cur3, syn3, mem3)\n",
        "\n",
        "#             spk3_rec.append(spk3)\n",
        "#             mem3_rec.append(mem3)\n",
        "\n",
        "#         return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
        "\n",
        "# net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WcBkni9VaB5D"
      },
      "source": [
        "Professor Lu has kidnapped my daughter and won't return her until I hit 99.99% accuracy, please help\n",
        "-JE"
      ]
    }
  ]
}